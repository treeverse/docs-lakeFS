

<!DOCTYPE html>

<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  <link rel="stylesheet" href="/v0.90/assets/css/just-the-docs-default.css">

  

  
    <script src="/v0.90/assets/js/vendor/lunr.min.js"></script>
  

  

  <script src="/v0.90/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  
  
    <link rel="icon" href="/v0.90/favicon.ico" type="image/x-icon">
  

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Garbage Collection | lakeFS</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Garbage Collection" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Clean up unnecessary objects using the garbage collection feature in lakeFS." />
<meta property="og:description" content="Clean up unnecessary objects using the garbage collection feature in lakeFS." />
<meta property="og:site_name" content="lakeFS" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Garbage Collection" />
<script type="application/ld+json">
{"description":"Clean up unnecessary objects using the garbage collection feature in lakeFS.","@type":"WebPage","headline":"Garbage Collection","url":"/v0.90/howto/garbage-collection.html","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/v0.90/assets/logo.svg"}},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Google Tag Manager Head -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-KTZBZW9');</script>
<!-- End Google Tag Manager Head -->
<meta name="robots" content="noindex">
<meta property="og:image" content="/v0.90/assets/img/shared-image.png">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/fontawesome.min.css" integrity="sha512-giQeaPns4lQTBMRpOOHsYnGw1tGVzbAIHUyHRgn7+6FmiEgGGjaG0T2LZJmAPMzRCl+Cug0ItQ2xDZpTmEc+CQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha512-MV7K8+y+gLIBoVD59lQIYicR65iaqukzvf/nwasF0nqhPay5w/9lJmVM2hMDcnK1OnMGCdVK+iQrJ7lzPJQd1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.13.2/themes/smoothness/jquery-ui.css">
<script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
<script src="/v0.90/assets/js/copy-code.js"></script>
<script>
    $(function () {
        $(".tabs").tabs();
    });
</script>
<script src="/v0.90/assets/js/feedback.js"></script>


</head>

<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KTZBZW9"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-link" viewBox="0 0 24 24">
        <title>Link</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
             class="feather feather-link">
            <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
            <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
        </svg>
    </symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
        <title>Search</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
             class="feather feather-search">
            <circle cx="11" cy="11" r="8"></circle>
            <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
        </svg>
    </symbol>
    <symbol id="svg-menu" viewBox="0 0 24 24">
        <title>Menu</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="20px" height="16px" viewBox="0 0 20 16" version="1.1"
             class="feather feather-menu">
            <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <g id="header-/-mobile" transform="translate(-30.000000, -32.000000)" fill="#279890">
                    <g id="Group" transform="translate(30.000000, 32.000000)">
                        <path
                                d="M20,14 L20,16 L0,16 L0,14 L20,14 Z M20,7 L20,9 L0,9 L0,7 L20,7 Z M20,0 L20,2 L0,2 L0,0 L20,0 Z"
                                id="mobile-menu" />
                    </g>
                </g>
            </g>
        </svg>
    </symbol>
    <symbol id="svg-arrow-right" viewBox="0 0 24 24">
        <title>Expand</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
             class="feather feather-chevron-right">
            <polyline points="9 18 15 12 9 6"></polyline>
        </svg>
    </symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
        <title>Document</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
             class="feather feather-file">
            <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path>
            <polyline points="13 2 13 9 20 9"></polyline>
        </svg>
    </symbol>
</svg>
<div class="body-wrapper">
    <div class="side-bar">
        <div class="site-header">
            <a href="https://lakefs.io" class="site-title lh-tight">
  <div class="site-logo"></div>

</a>
            <a href="#" id="menu-button" class="site-button">
                <svg viewBox="0 0 24 24" class="icon">
                    <use xlink:href="#svg-menu"></use>
                </svg>
            </a>
        </div>
        <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav">
            
            <div class="search">
                <div class="search-input-wrap">
                    <input type="text" id="search-input" class="search-input" tabindex="0"
                           placeholder="Search lakeFS" aria-label="Search lakeFS"
                           autocomplete="off">
                    <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon">
                            <use xlink:href="#svg-search"></use>
                        </svg></label>
                </div>
                <div id="search-results" class="search-results"></div>
            </div>
            

            <div class="nav-category nav-version">
                <label for="selectversion">Version:</label>
                <select id="selectversion" name="version" onchange="javascript:location.href = '/' + encodeURI(this.value);">
                    <option value="" selected>Latest</option>
                </select>
            </div>
            <script async>
                window.addEventListener("load",  async () => {
                    const pathFirstLevel = location.pathname.split('/')[1];
                    const selectedVersion = pathFirstLevel.startsWith('v') && pathFirstLevel || '';
                    const selectVersionElmFirst = document.getElementById('selectversion').firstElementChild;
                    const response = await fetch('/versions.json');
                    if (!response.ok) {
                        return
                    }
                    const versions = await response.json();
                    for (let [key, value] of Object.entries(versions)) {
                        const el = document.createElement("option");
                        el.value = key;
                        el.textContent = value;
                        if (key === selectedVersion) {
                            el.selected = true;
                        }
                        selectVersionElmFirst.after(el);
                    }
                });
            </script>

            <ul class="nav-list"><li
            class="nav-list-item"><a href="/v0.90/"
           class="nav-list-link">What is lakeFS</a></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.90/quickstart/"
           class="nav-list-link">Quickstart</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.90/quickstart/run.html"
                   class="nav-list-link">Run lakeFS</a></li><li class="nav-list-item "><a href="/v0.90/quickstart/repository.html"
                   class="nav-list-link">Create a Repository</a></li><li class="nav-list-item "><a href="/v0.90/quickstart/add_data.html"
                   class="nav-list-link">Add Data</a></li><li class="nav-list-item "><a href="/v0.90/quickstart/first_commit.html"
                   class="nav-list-link">Commit the Changes</a></li><li class="nav-list-item "><a href="/v0.90/quickstart/more_quickstart_options.html"
                   class="nav-list-link">More Quickstart Options</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.90/deploy/"
           class="nav-list-link">Deploy and Setup lakeFS</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.90/deploy/aws.html"
                   class="nav-list-link">AWS</a></li><li class="nav-list-item "><a href="/v0.90/deploy/azure.html"
                   class="nav-list-link">Azure</a></li><li class="nav-list-item "><a href="/v0.90/deploy/gcp.html"
                   class="nav-list-link">GCP</a></li><li class="nav-list-item "><a href="/v0.90/deploy/onprem.html"
                   class="nav-list-link">On-Prem</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.90/integrations/"
           class="nav-list-link">Integrations</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.90/integrations/spark.html"
                   class="nav-list-link">Spark</a></li><li class="nav-list-item "><a href="/v0.90/integrations/delta.html"
                   class="nav-list-link">Delta Lake</a></li><li class="nav-list-item "><a href="/v0.90/integrations/aws_cli.html"
                   class="nav-list-link">AWS CLI</a></li><li class="nav-list-item "><a href="/v0.90/integrations/airflow.html"
                   class="nav-list-link">Airflow</a></li><li class="nav-list-item "><a href="/v0.90/integrations/python.html"
                   class="nav-list-link">Python</a></li><li class="nav-list-item "><a href="/v0.90/integrations/duckdb.html"
                   class="nav-list-link">DuckDB</a></li><li class="nav-list-item "><a href="/v0.90/integrations/glue_hive_metastore.html"
                   class="nav-list-link">Glue / Hive metastore</a></li><li class="nav-list-item "><a href="/v0.90/integrations/presto_trino.html"
                   class="nav-list-link">Presto/Trino</a></li><li class="nav-list-item "><a href="/v0.90/integrations/athena.html"
                   class="nav-list-link">Amazon Athena</a></li><li class="nav-list-item "><a href="/v0.90/integrations/kubeflow.html"
                   class="nav-list-link">Kubeflow</a></li><li class="nav-list-item "><a href="/v0.90/integrations/airbyte.html"
                   class="nav-list-link">Airbyte</a></li><li class="nav-list-item "><a href="/v0.90/integrations/dbt.html"
                   class="nav-list-link">dbt</a></li><li class="nav-list-item "><a href="/v0.90/integrations/kakfa.html"
                   class="nav-list-link">Kafka</a></li><li class="nav-list-item "><a href="/v0.90/integrations/sagemaker.html"
                   class="nav-list-link">SageMaker</a></li><li class="nav-list-item "><a href="/v0.90/integrations/hive.html"
                   class="nav-list-link">Hive</a></li><li class="nav-list-item "><a href="/v0.90/integrations/dremio.html"
                   class="nav-list-link">Dremio</a></li><li class="nav-list-item "><a href="/v0.90/integrations/iceberg.html"
                   class="nav-list-link">Iceberg</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.90/hooks/"
           class="nav-list-link">Hooks</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.90/hooks/overview.html"
                   class="nav-list-link">Overview</a></li><li class="nav-list-item "><a href="/v0.90/hooks/lua.html"
                   class="nav-list-link">Lua</a></li><li class="nav-list-item "><a href="/v0.90/hooks/webhooks.html"
                   class="nav-list-link">Webhooks</a></li><li class="nav-list-item "><a href="/v0.90/hooks/airflow.html"
                   class="nav-list-link">Airflow</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.90/use_cases/"
           class="nav-list-link">Use Cases</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.90/use_cases/etl_testing.html"
                   class="nav-list-link">ETL Testing Environment</a></li><li class="nav-list-item "><a href="/v0.90/use_cases/rollback.html"
                   class="nav-list-link">Rollback</a></li><li class="nav-list-item "><a href="/v0.90/use_cases/reproducibility.html"
                   class="nav-list-link">Reproducibility</a></li><li class="nav-list-item "><a href="/v0.90/use_cases/cicd_for_data.html"
                   class="nav-list-link">CI/CD for data lakes</a></li></ul></li><li
            class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.90/howto/"
           class="nav-list-link">How-To</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.90/howto/import.html"
                   class="nav-list-link">Import data into lakeFS</a></li><li class="nav-list-item  active"><a href="/v0.90/howto/garbage-collection.html"
                   class="nav-list-link active">Garbage Collection</a></li><li class="nav-list-item "><a href="/v0.90/howto/upgrade.html"
                   class="nav-list-link">Upgrade lakeFS</a></li><li class="nav-list-item "><a href="/v0.90/howto/export.html"
                   class="nav-list-link">Exporting Data</a></li><li class="nav-list-item "><a href="/v0.90/howto/copying.html"
                   class="nav-list-link">Copying data to/from lakeFS</a></li><li class="nav-list-item "><a href="/v0.90/howto/protect-branches.html"
                   class="nav-list-link">Protect Branches</a></li><li class="nav-list-item "><a href="/v0.90/howto/migrate-away.html"
                   class="nav-list-link">Migrating away from lakeFS</a></li><li class="nav-list-item "><a href="/v0.90/howto/sizing-guide.html"
                   class="nav-list-link">Sizing Guide</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.90/reference/"
           class="nav-list-link">Reference</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.90/reference/configuration.html"
                   class="nav-list-link">Configuration</a></li><li class="nav-list-item "><a href="/v0.90/reference/cli.html"
                   class="nav-list-link">CLI (lakectl)</a></li><li class="nav-list-item "><a href="/v0.90/reference/api.html"
                   class="nav-list-link">API Reference</a></li><li class="nav-list-item "><a href="/v0.90/reference/spark-client.html"
                   class="nav-list-link">Spark Client</a></li><li class="nav-list-item "><a href="/v0.90/reference/s3.html"
                   class="nav-list-link">S3 Supported API</a></li><li class="nav-list-item "><a href="/v0.90/reference/authentication.html"
                   class="nav-list-link">Authentication</a></li><li class="nav-list-item "><a href="/v0.90/reference/saml-authentication-integration.html"
                   class="nav-list-link">SAML Authentication Integration</a></li><li class="nav-list-item "><a href="/v0.90/reference/authorization.html"
                   class="nav-list-link">Authorization</a></li><li class="nav-list-item "><a href="/v0.90/reference/monitor.html"
                   class="nav-list-link">Monitoring using Prometheus</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.90/understand/"
           class="nav-list-link">Understanding lakeFS</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.90/understand/architecture.html"
                   class="nav-list-link">Architecture</a></li><li class="nav-list-item "><a href="/v0.90/understand/model.html"
                   class="nav-list-link">Model</a></li><li class="nav-list-item "><a href="/v0.90/understand/performance-best-practices.html"
                   class="nav-list-link">Performance Best Practices</a></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                        <use xlink:href="#svg-arrow-right"></use>
                    </svg></a><a href="/v0.90/understand/how/"
                   class="nav-list-link">How it Works</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/v0.90/understand/how/versioning-internals.html"
                           class="nav-list-link">Versioning Internals</a>
                    </li><li class="nav-list-item ">
                        <a href="/v0.90/understand/how/kv.html"
                           class="nav-list-link">Internal database structure</a>
                    </li><li class="nav-list-item ">
                        <a href="/v0.90/understand/how/merge.html"
                           class="nav-list-link">Merge</a>
                    </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                        <use xlink:href="#svg-arrow-right"></use>
                    </svg></a><a href="/v0.90/understand/data_lifecycle_management/"
                   class="nav-list-link">Data Lifecycle Management</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/v0.90/understand/data_lifecycle_management/data-devenv.html"
                           class="nav-list-link">In Test</a>
                    </li><li class="nav-list-item ">
                        <a href="/v0.90/understand/data_lifecycle_management/ci.html"
                           class="nav-list-link">During Deployment</a>
                    </li><li class="nav-list-item ">
                        <a href="/v0.90/understand/data_lifecycle_management/production.html"
                           class="nav-list-link">In Production</a>
                    </li></ul></li><li class="nav-list-item "><a href="/v0.90/understand/glossary.html"
                   class="nav-list-link">Glossary</a></li></ul></li><li
            class="nav-list-item"><a href="/v0.90/roadmap.html"
           class="nav-list-link">Roadmap</a></li><li
            class="nav-list-item"><a href="/v0.90/commitment.html"
           class="nav-list-link">Commitment to OSS</a></li><li
            class="nav-list-item"><a href="/v0.90/contributing.html"
           class="nav-list-link">Contributing</a></li><li
            class="nav-list-item"><a href="/v0.90/faq.html"
           class="nav-list-link">FAQ</a></li></ul>
            <div class="mobile-menu">
                
<nav aria-label="Auxiliary" class="aux-nav">
    <ul class="aux-nav-list">
        
        
        <li class="aux-nav-list-item">
            <a href="https://docs.lakefs.io/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Docs
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://lakefs.io/blog/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Blog
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://lakefs.io/community/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Community
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://github.com/treeverse/lakeFS" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                GitHub
            </a>
        </li>
        
        
        
        
        <li class="aux-nav-list-item button">
            <a href="https://lakefs.io/cloud-registration/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                lakeFS Cloud
            </a>
        </li>
        
        
    </ul>
</nav>

            </div>
        </nav>

    </div>
    <div class="main" id="top">
         <div class="feedback-container">
            <div id="is-helpful-ty">
                <div class="text-epsilon">Thank you for your feedback.</div>
                <div class="mt-2 text-epsilon">
                    <a href="https://lakefs.io/slack" target="_blank">Join the community</a> to get more help.
                </div>
            </div>
            <div class="feedback-buttons">
                <span class="tooltip">
                    <button class="page-helpful-btn far fa-lg fa-thumbs-up" id="page-helpful-yes"></button>
                    <span class="tooltiptext">
                        This page is <b>helpful</b>
                    </span>
                </span>
                <span class="tooltip">
                    <button class="page-helpful-btn far fa-lg fa-thumbs-down" id="page-helpful-no"></button>
                    <span class="tooltiptext">
                        This page is <b>not helpful</b>
                    </span>
                </span>
            </div>
        </div>
        <div id="main-header" class="main-header">
            
<nav aria-label="Auxiliary" class="aux-nav">
    <ul class="aux-nav-list">
        
        
        <li class="aux-nav-list-item">
            <a href="https://docs.lakefs.io/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Docs
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://lakefs.io/blog/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Blog
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://lakefs.io/community/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Community
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://github.com/treeverse/lakeFS" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                GitHub
            </a>
        </li>
        
        
        
        
        <li class="aux-nav-list-item button">
            <a href="https://lakefs.io/cloud-registration/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                lakeFS Cloud
            </a>
        </li>
        
        
    </ul>
</nav>

        </div>
        <div id="main-content-wrap" class="main-content-wrap">
            
            
            <nav aria-label="Breadcrumb" class="breadcrumb-nav">
                <ol class="breadcrumb-nav-list">
                    
                    <li class="breadcrumb-nav-list-item"><a href="/v0.90/howto/">How-To</a>
                    </li>
                    
                    <li class="breadcrumb-nav-list-item"><span>Garbage Collection</span></li>
                </ol>
            </nav>
            
            
            <div id="main-content" class="main-content" role="main">
                
                <h1 class="no_toc" id="garbage-collection">
  
  
    <a href="#garbage-collection" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Garbage Collection
  
  
</h1>
    

<p class="note">Note: For managed garbage collection on top of a hosted lakeFS service with guaranteed SLAs, try <a href="https://lakefs.cloud">lakeFS cloud</a></p>

<p>By default, lakeFS keeps all your objects forever. This allows you to travel back in time to previous versions of your data.
However, sometimes you may want to hard-delete your objects - namely, delete them from the underlying storage. 
Reasons for this include cost-reduction and privacy policies.</p>

<p>Garbage collection rules in lakeFS define for how long to retain objects after they have been deleted (see more information <a href="#considerations">below</a>).
lakeFS provides a Spark program to hard-delete objects that have been deleted and whose retention period has ended according to the GC rules.
The GC job does not remove any commits: you will still be able to use commits containing hard-deleted objects,
but trying to read these objects from lakeFS will result in a <code class="language-plaintext highlighter-rouge">410 Gone</code> HTTP status.</p>

<p class="note"><strong>Note</strong>
At this point, lakeFS supports Garbage Collection only on S3 and Azure.  We have <a href="https://github.com/treeverse/lakeFS/issues/3626">concrete plans</a> to extend the support to GCP.</p>

<ol class="pb-5" id="markdown-toc">
  <li><a href="#understanding-garbage-collection" id="markdown-toc-understanding-garbage-collection">Understanding Garbage Collection</a>    <ol>
      <li><a href="#what-gets-collected" id="markdown-toc-what-gets-collected">What gets collected</a></li>
      <li><a href="#what-does-not-get-collected" id="markdown-toc-what-does-not-get-collected">What does <em>not</em> get collected</a></li>
    </ol>
  </li>
  <li><a href="#configuring-gc-rules" id="markdown-toc-configuring-gc-rules">Configuring GC rules</a></li>
  <li><a href="#running-the-gc-job" id="markdown-toc-running-the-gc-job">Running the GC job</a>    <ol>
      <li><a href="#gc-job-options" id="markdown-toc-gc-job-options">GC job options</a>        <ol>
          <li><a href="#mark-only-mode" id="markdown-toc-mark-only-mode">Mark only mode</a></li>
          <li><a href="#sweep-only-mode" id="markdown-toc-sweep-only-mode">Sweep only mode</a></li>
          <li><a href="#performance" id="markdown-toc-performance">Performance</a></li>
          <li><a href="#networking" id="markdown-toc-networking">Networking</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#considerations" id="markdown-toc-considerations">Considerations</a></li>
  <li><a href="#gc-backup-and-restore" id="markdown-toc-gc-backup-and-restore">GC backup and restore</a>    <ol>
      <li><a href="#using-rclone" id="markdown-toc-using-rclone">Using rclone</a>        <ol>
          <li><a href="#backup-command" id="markdown-toc-backup-command">Backup command</a></li>
          <li><a href="#restore-command" id="markdown-toc-restore-command">Restore command</a></li>
          <li><a href="#example" id="markdown-toc-example">Example</a></li>
        </ol>
      </li>
      <li><a href="#using-distcp" id="markdown-toc-using-distcp">Using DistCp</a></li>
    </ol>
  </li>
  <li><a href="#beta-deleting-uncommitted-objects" id="markdown-toc-beta-deleting-uncommitted-objects">Beta: Deleting uncommitted objects</a>    <ol>
      <li><a href="#running-the-uncommitted-gc" id="markdown-toc-running-the-uncommitted-gc">Running the uncommitted GC</a></li>
    </ol>
  </li>
</ol>
<h2 id="understanding-garbage-collection">
  
  
    <a href="#understanding-garbage-collection" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Understanding Garbage Collection
  
  
</h2>
    

<p>For every branch, the GC job retains deletes objects for the number of days defined for the branch.
In the absence of a branch-specific rule, the default rule for the repository is used.
If an object is present in more than one branch ancestry, it’s retained according to the rule with the largest number of days between those branches.
That is, it’s hard-deleted only after the retention period has ended for all relevant branches.</p>

<p>Example GC rules for a repository:</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"default_retention_days"</span><span class="p">:</span><span class="w"> </span><span class="mi">14</span><span class="p">,</span><span class="w">
  </span><span class="nl">"branches"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="nl">"branch_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"main"</span><span class="p">,</span><span class="w"> </span><span class="nl">"retention_days"</span><span class="p">:</span><span class="w"> </span><span class="mi">21</span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="nl">"branch_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"dev"</span><span class="p">,</span><span class="w"> </span><span class="nl">"retention_days"</span><span class="p">:</span><span class="w"> </span><span class="mi">7</span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>In the above example, objects are retained for 14 days after deletion by default. However, if they are present in the branch <code class="language-plaintext highlighter-rouge">main</code>, they are retained for 21 days.
Objects present in the <code class="language-plaintext highlighter-rouge">dev</code> branch (but not in any other branch) are retained for 7 days after they are deleted.</p>
<h3 id="what-gets-collected">
  
  
    <a href="#what-gets-collected" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What gets collected
  
  
</h3>
    

<p>Because each object in lakeFS may be accessible from multiple branches, it
might not be obvious which objects will be considered garbage and collected.</p>

<p>Garbage collection is configured by specifying the number of days to retain
objects on each branch. If a branch is configured to retain objects for a
given number of days, any object that was accessible from the HEAD of a
branch in that past number of days will be retained.</p>

<p>The garbage collection process proceeds in three main phases:</p>

<ul>
  <li>
    <p><strong>Discover which commits will retain their objects.</strong>  For every branch,
the garbage collection job looks at the HEAD of the branch that many days
ago; every commit at or since that HEAD must be retained.</p>

    <p><img src="/v0.90/assets/img/gc-sample-commits.png" alt="mermaid diagram" /></p>

    <p>Continuing the example, branch <code class="language-plaintext highlighter-rouge">main</code> retains for 21 days and branch <code class="language-plaintext highlighter-rouge">dev</code>
for 7. When running GC on 2022-03-31:</p>

    <ul>
      <li>7 days ago, on 2022-03-24 the head of branch <code class="language-plaintext highlighter-rouge">dev</code> was <code class="language-plaintext highlighter-rouge">d:
2022-03-23</code>. So, that commit is retained (along with all more recent
commits on <code class="language-plaintext highlighter-rouge">dev</code>) but all older commits <code class="language-plaintext highlighter-rouge">d: *</code> will be collected.</li>
      <li>21 days ago, on 2022-03-10, the head of branch <code class="language-plaintext highlighter-rouge">main</code> was
<code class="language-plaintext highlighter-rouge">2022-03-09</code>. So that commit is retained (along with all more recent
commits on <code class="language-plaintext highlighter-rouge">main</code>) but commits <code class="language-plaintext highlighter-rouge">2022-02-27</code> and <code class="language-plaintext highlighter-rouge">2022-03-01</code> will be
collected.</li>
    </ul>
  </li>
  <li>
    <p><strong>Discover which objects need to be garbage collected.</strong> Hold (<em>only</em>)
objects accessible on some retained commits.</p>

    <p>In the example, all objects of commit <code class="language-plaintext highlighter-rouge">2022-03-12</code>, for instance, are
retained. This <em>includes</em> objects added in previous commits. However,
objects added in commit <code class="language-plaintext highlighter-rouge">d: 2022-03-14</code> which were overwritten or
deleted in commit <code class="language-plaintext highlighter-rouge">d: 2022-03-20</code> are not visible in any retained commit
and will be garbage collected.</p>
  </li>
  <li>
    <p><strong>Garbage collect those objects by deleting them.</strong> The data of any
deleted object will no longer be accessible. lakeFS retains all metadata
about the object, but attempting to read it via the lakeFS API or the S3
gateway will return HTTP status 410 (“Gone”).</p>
  </li>
</ul>
<h3 id="what-does-not-get-collected">
  
  
    <a href="#what-does-not-get-collected" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What does <em>not</em> get collected
  
  
</h3>
    

<p>Some objects will <em>not</em> be collected regardless of configured GC rules:</p>
<ul>
  <li>Any object that is accessible from any branch’s HEAD.</li>
  <li>Objects stored outside the repository’s <a href="/v0.90/understand/glossary.html#storage-namespace">storage namespace</a>.
For example, objects imported using the lakeFS import UI are not collected.</li>
  <li>Uncommitted objects, see <a href="#Beta:-Deleting-uncommitted-objects">below</a>,</li>
</ul>
<h2 id="configuring-gc-rules">
  
  
    <a href="#configuring-gc-rules" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Configuring GC rules
  
  
</h2>
    
<h3 class="no_toc" id="using-lakectl">
  
  
    <a href="#using-lakectl" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Using lakectl
  
  
</h3>
    

<p>Use the <code class="language-plaintext highlighter-rouge">lakectl</code> CLI to define the GC rules:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt;&gt; example_repo_gc_rules.json
{
  "default_retention_days": 14,
  "branches": [
    {"branch_id": "main", "retention_days": 21},
    {"branch_id": "dev", "retention_days": 7}
  ]
}
</span><span class="no">EOT

</span>lakectl gc set-config lakefs://example-repo <span class="nt">-f</span> example_repo_gc_rules.json 
</code></pre></div></div>
<h3 class="no_toc" id="from-the-lakefs-ui">
  
  
    <a href="#from-the-lakefs-ui" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> From the lakeFS UI
  
  
</h3>
    

<ol>
  <li>Navigate to the main page of your repository.</li>
  <li>Go to <em>Settings</em> -&gt; <em>Retention</em>.</li>
  <li>Click <em>Edit policy</em> and paste your GC rule into the text box as a JSON.</li>
  <li>Save your changes.</li>
</ol>

<p><img src="/v0.90/assets/img/gc_rules_from_ui.png" alt="GC Rules From UI" /></p>
<h2 id="running-the-gc-job">
  
  
    <a href="#running-the-gc-job" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Running the GC job
  
  
</h2>
    

<p>The GC job is a Spark program that can be run using <code class="language-plaintext highlighter-rouge">spark-submit</code> (or using your preferred method of running Spark programs).
The job will hard-delete objects that were deleted and whose retention period has ended according to the GC rules.</p>

<p>First, you’ll have to download the lakeFS Spark client Uber-jar. The Uber-jar can be found on a public S3 location:</p>

<p>For Spark 2.4.7: <br />
http://treeverse-clients-us-east.s3-website-us-east-1.amazonaws.com/lakefs-spark-client-247/${CLIENT_VERSION}/lakefs-spark-client-247-assembly-${CLIENT_VERSION}.jar</p>

<p>For Spark 3.0.1: <br />
http://treeverse-clients-us-east.s3-website-us-east-1.amazonaws.com/lakefs-spark-client-301/${CLIENT_VERSION}/lakefs-spark-client-301-assembly-${CLIENT_VERSION}.jar</p>

<p><code class="language-plaintext highlighter-rouge">CLIENT_VERSION</code>s for Spark 2.4.7 can be found <a href="https://mvnrepository.com/artifact/io.lakefs/lakefs-spark-client-247">here</a>, and for Spark 3.0.1 they can be found <a href="https://mvnrepository.com/artifact/io.lakefs/lakefs-spark-client-301">here</a>.</p>

<p>Running instructions:</p>

<div class="tabs">
  <ul>
    <li><a href="#aws-option">On AWS</a></li>
	<li><a href="#azure-option">On Azure</a></li>
  </ul>
  <div id="aws-option">
    <p>You should specify the Uber-jar path instead of <code class="language-plaintext highlighter-rouge">&lt;APPLICATION-JAR-PATH&gt;</code> and run the following command to make the garbage collector start running:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit <span class="nt">--class</span> io.treeverse.clients.GarbageCollector <span class="se">\</span>
  <span class="nt">--packages</span> org.apache.hadoop:hadoop-aws:2.7.7 <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.lakefs.api.url<span class="o">=</span>https://lakefs.example.com:8000/api/v1  <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.lakefs.api.access_key<span class="o">=</span>&lt;LAKEFS_ACCESS_KEY&gt; <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.lakefs.api.secret_key<span class="o">=</span>&lt;LAKEFS_SECRET_KEY&gt; <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.s3a.access.key<span class="o">=</span>&lt;S3_ACCESS_KEY&gt; <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.s3a.secret.key<span class="o">=</span>&lt;S3_SECRET_KEY&gt; <span class="se">\</span>
  &lt;APPLICATION-JAR-PATH&gt; <span class="se">\</span>
  example-repo us-east-1
</code></pre></div>    </div>
  </div>

  <div id="azure-option">
    <p>You should run the following command to make the garbage collector start running:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit <span class="nt">--class</span> io.treeverse.clients.GarbageCollector <span class="se">\</span>
  <span class="nt">--packages</span> org.apache.hadoop:hadoop-aws:3.2.1 <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.lakefs.api.url<span class="o">=</span>https://lakefs.example.com:8000/api/v1  <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.lakefs.api.access_key<span class="o">=</span>&lt;LAKEFS_ACCESS_KEY&gt; <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.lakefs.api.secret_key<span class="o">=</span>&lt;LAKEFS_SECRET_KEY&gt; <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.azure.account.key.&lt;AZURE_STORAGE_ACCOUNT&gt;.dfs.core.windows.net<span class="o">=</span>&lt;AZURE_STORAGE_ACCESS_KEY&gt; <span class="se">\</span>
  s3://treeverse-clients-us-east/lakefs-spark-client-312-hadoop3/0.6.1/lakefs-spark-client-312-hadoop3-assembly-0.6.1.jar <span class="se">\</span>
  example-repo
</code></pre></div>    </div>

    <p><strong>Notes:</strong></p>
    <ul>
      <li>To run GC on Azure, use <code class="language-plaintext highlighter-rouge">lakefs-spark-client-312-hadoop3</code> only. This client is compiled for Spark 3.1.2 with Hadoop 3.2.1, but may work with other Spark versions and higher Hadoop versions. Specifically, this client was tested on Databricks runtime DBR 11.0 (Spark 3.3.0, 3.3.2).</li>
      <li>GC on Azure is supported from Spark client version &gt;= v0.2.0.</li>
      <li>In case you don’t have <code class="language-plaintext highlighter-rouge">hadoop-azure</code> package as part of your environment, you should add the package to your spark-submit with <code class="language-plaintext highlighter-rouge">--packages org.apache.hadoop:hadoop-azure:3.2.1</code></li>
      <li>For GC to work on Azure blob, <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/soft-delete-blob-overview">soft delete</a> should be disabled.</li>
    </ul>

  </div>

  <p>The list of expired objects is written in Parquet format in the storage
namespace of the bucket under <code class="language-plaintext highlighter-rouge">_lakefs/retention/gc/addresses/mark_id=MARK_ID</code>, where MARK_ID identifies the run.</p>

  <p><strong>Note:</strong> if you are running lakeFS Spark client of version &lt; v0.4.0, this file is located under <code class="language-plaintext highlighter-rouge">_lakefs/retention/gc/addresses/run_id=RUN_ID</code>,
where RUN_ID identifies the run.</p>
<h3 id="gc-job-options">
  
  
    <a href="#gc-job-options" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> GC job options
  
  
</h3>
    

  <p>By default, GC first creates a list of expired objects according to your retention rules and then hard-deletes those objects. 
However, you can use GC options to break the GC job down into two stages:</p>
  <ol>
    <li>Mark stage: GC will mark the expired objects to hard-delete, <strong>without</strong> deleting them.</li>
    <li>Sweep stage: GC will hard-delete objects marked by a previous mark-only GC run.</li>
  </ol>

  <p>By breaking GC into these stages, you can pause and create a backup of the objects that GC is about to sweep and later 
restore them. You can use the <a href="#gc-backup-and-restore">GC backup and restore</a> utility to do that.</p>
<h4 id="mark-only-mode">
  
  
    <a href="#mark-only-mode" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Mark only mode
  
  
</h4>
    

  <p>To make GC run the mark stage only, add the following properties to your spark-submit command:</p>
  <div class="language-properties highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="py">spark.hadoop.lakefs.gc.do_sweep</span><span class="p">=</span><span class="s">false</span>
<span class="py">spark.hadoop.lakefs.gc.mark_id</span><span class="p">=</span><span class="s">&lt;MARK_ID&gt; # Replace &lt;MARK_ID&gt; with your own identification string. This MARK_ID will enable you to start a sweep (actual deletion) run later</span>
</code></pre></div>  </div>
  <p>Running in mark only mode, GC will write the addresses of the expired objects to delete to the following location: <code class="language-plaintext highlighter-rouge">STORAGE_NAMESPACE/_lakefs/retention/gc/addresses/mark_id=&lt;MARK_ID&gt;/</code> as a parquet.</p>

  <p><strong>Notes:</strong></p>
  <ul>
    <li>Mark only mode is only available from v0.4.0 of lakeFS Spark client.</li>
    <li>The <code class="language-plaintext highlighter-rouge">spark.hadoop.lakefs.debug.gc.no_delete</code> property has been deprecated with v0.4.0.</li>
  </ul>
<h4 id="sweep-only-mode">
  
  
    <a href="#sweep-only-mode" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Sweep only mode
  
  
</h4>
    

  <p>To make GC run the sweep stage only, add the following properties to your spark-submit command:</p>
  <div class="language-properties highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="py">spark.hadoop.lakefs.gc.do_mark</span><span class="p">=</span><span class="s">false</span>
<span class="py">spark.hadoop.lakefs.gc.mark_id</span><span class="p">=</span><span class="s">&lt;MARK_ID&gt; # Replace &lt;MARK_ID&gt; with the identifier you used on a previous mark-only run</span>
</code></pre></div>  </div>
  <p>Running in sweep only mode, GC will hard-delete the expired objects marked by a mark-only run and listed in: <code class="language-plaintext highlighter-rouge">STORAGE_NAMESPACE/_lakefs/retention/gc/addresses/mark_id=&lt;MARK_ID&gt;/</code>.</p>

  <p><strong>Note:</strong> Mark only mode is only available from v0.4.0 of lakeFS Spark client.</p>
<h4 id="performance">
  
  
    <a href="#performance" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Performance
  
  
</h4>
    

  <p>Garbage collection reads many commits.  It uses Spark to spread the load of
reading the contents of all of these commits.  For very large jobs running
on very large clusters, you may want to tweak this load.  To do this:</p>

  <ul>
    <li>Add <code class="language-plaintext highlighter-rouge">-c spark.hadoop.lakefs.gc.range.num_partitions=RANGE_PARTITIONS</code>
(default 50) to spread the initial load of reading commits across more
Spark executors.</li>
    <li>Add <code class="language-plaintext highlighter-rouge">-c spark.hadoop.lakefs.gc.address.num_partitions=RANGE_PARTITIONS</code>
(default 200) to spread the load of reading all objects included in a
commit across more Spark executors.</li>
  </ul>

  <p>Normally this should not be needed.</p>
<h4 id="networking">
  
  
    <a href="#networking" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Networking
  
  
</h4>
    

  <p>Garbage collection communicates with the lakeFS server.  Very large
repositories may require increasing a read timeout.  If you run into timeout errors during communication from the Spark job to lakefs consider increasing these timeouts:</p>

  <ul>
    <li>Add <code class="language-plaintext highlighter-rouge">-c spark.hadoop.lakefs.api.read.timeout_seconds=TIMEOUT_IN_SECONDS</code>
(default 10) to allow lakeFS more time to respond to requests.</li>
    <li>Add <code class="language-plaintext highlighter-rouge">-c
spark.hadoop.lakefs.api.connection.timeout_seconds=TIMEOUT_IN_SECONDS</code>
(default 10) to wait longer for lakeFS to accept connections.</li>
  </ul>
<h2 id="considerations">
  
  
    <a href="#considerations" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Considerations
  
  
</h2>
    

  <ol>
    <li>
      <p>In order for an object to be hard-deleted, it must be deleted from all branches.
You should remove stale branches to prevent them from retaining old objects.
For example, consider a branch that has been merged to <code class="language-plaintext highlighter-rouge">main</code> and has become stale.
An object which is later deleted from <code class="language-plaintext highlighter-rouge">main</code> will always be present in the stale branch, preventing it from being hard-deleted.</p>
    </li>
    <li>
      <p>lakeFS will never delete objects outside your repository’s storage namespace.
In particular, objects that were imported using <code class="language-plaintext highlighter-rouge">lakectl ingest</code> or <code class="language-plaintext highlighter-rouge">UI Import Wizard</code> will not be affected by GC jobs.</p>
    </li>
    <li>
      <p>In cases where deleted objects are brought back to life while a GC job is running, said objects may or may not be
deleted. Such actions include:</p>
      <ol>
        <li>Reverting a commit in which a file was deleted.</li>
        <li>Branching out from an old commit.</li>
        <li>Expanding the retention period of a branch.</li>
        <li>Creating a branch from an existing branch, where the new branch has a longer retention period.</li>
      </ol>
    </li>
  </ol>
<h2 id="gc-backup-and-restore">
  
  
    <a href="#gc-backup-and-restore" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> GC backup and restore
  
  
</h2>
    

  <p>GC was created to hard-delete objects from your underlying objects store according to your retention rules. However, when you start
using the feature you may want to first gain confidence in the decisions GC makes. The GC backup and restore utility helps you do that.</p>

  <p><strong>Use-cases:</strong></p>
  <ul>
    <li>Backup: copy expired objects from your repository’s storage namespace to an external location before running GC in <a href="#sweep-only-mode">sweep only mode</a>.</li>
    <li>Restore: copy objects that were hard-deleted by GC from an external location you used for saving your backup into your repository’s storage namespace.</li>
  </ul>
<h3 id="using-rclone">
  
  
    <a href="#using-rclone" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Using rclone
  
  
</h3>
    

  <p>Follow <a href="https://rclone.org/docs/">rclone documentation</a> to configure remote access to the underlying storage used by lakeFS.
Replace <code class="language-plaintext highlighter-rouge">LAKEFS_STORAGE_NAMESPACE</code> with remote:bucket/path which points to the lakeFS repository storage namespace.
The <code class="language-plaintext highlighter-rouge">BACKUP_STORAGE_LOCATION</code> attribute points to a storage location outside your lakeFS storage namespace into which you want to save the backup.</p>
<h4 id="backup-command">
  
  
    <a href="#backup-command" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Backup command
  
  
</h4>
    

  <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rclone <span class="nt">--include</span> <span class="s2">"*.txt"</span> <span class="nb">cat</span> <span class="s2">"&lt;LAKEFS_STORAGE_NAMESPACE&gt;/_lakefs/retention/gc/addresses.text/mark_id=&lt;MARK_ID&gt;/"</span> | <span class="se">\</span>
  rclone <span class="nt">-P</span> <span class="nt">--no-traverse</span> <span class="nt">--files-from</span> - copy &lt;LAKEFS_STORAGE_NAMESPACE&gt; &lt;BACKUP_STORAGE_LOCATION&gt;
</code></pre></div>  </div>
<h4 id="restore-command">
  
  
    <a href="#restore-command" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Restore command
  
  
</h4>
    

  <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rclone <span class="nt">--include</span> <span class="s2">"*.txt"</span> <span class="nb">cat</span> <span class="s2">"&lt;LAKEFS_STORAGE_NAMESPACE&gt;/_lakefs/retention/gc/addresses.text/mark_id=&lt;MARK_ID&gt;/"</span> | <span class="se">\</span>
  rclone <span class="nt">-P</span> <span class="nt">--no-traverse</span> <span class="nt">--files-from</span> - copy &lt;BACKUP_STORAGE_LOCATION&gt; &lt;LAKEFS_STORAGE_NAMESPACE&gt;
</code></pre></div>  </div>
<h4 id="example">
  
  
    <a href="#example" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Example
  
  
</h4>
    

  <p>The following of commands used to backup/resource a configured remote ‘azure’ (Azure blob storage) to access example repository storange namespace <code class="language-plaintext highlighter-rouge">https://lakefs.blob.core.windows.net/repo/example/</code>:</p>

  <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Backup</span>
rclone <span class="nt">--include</span> <span class="s2">"*.txt"</span> <span class="nb">cat</span> <span class="s2">"azure://repo/example/_lakefs/retention/gc/addresses.text/mark_id=a64d1885-6202-431f-a0a3-8832e4a5865a/"</span> | <span class="se">\</span>
  rclone <span class="nt">-P</span> <span class="nt">--no-traverse</span> <span class="nt">--files-from</span> - copy azure://repo/example/ azure://backup/repo-example/

<span class="c"># Restore</span>
rclone <span class="nt">--include</span> <span class="s2">"*.txt"</span> <span class="nb">cat</span> <span class="s2">"azure://tal/azure-br/_lakefs/retention/gc/addresses.text/mark_id=a64d1885-6202-431f-a0a3-8832e4a5865a/"</span> | <span class="se">\</span>
  rclone <span class="nt">-P</span> <span class="nt">--no-traverse</span> <span class="nt">--files-from</span> - copy azure://backup/repo-example/ azure://repo/example/
</code></pre></div>  </div>
<h3 id="using-distcp">
  
  
    <a href="#using-distcp" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Using DistCp
  
  
</h3>
    

  <p>This utility is a Spark application that uses <a href="https://hadoop.apache.org/docs/current/hadoop-distcp/DistCp.html">DistCp</a> under the hood to copy objects marked by GC as expired from one location to another.</p>

  <p><strong>Notes</strong></p>
  <ul>
    <li>GC Backup &amp; Restore job using DistCp is <a href="https://github.com/treeverse/lakeFS/issues/4775">broken</a> due to changes in the storage namespace structure relevant to lakeFS &gt;= v0.84.0.  We’re working to fix it.</li>
    <li>There has been a change in the storage namespace structure relevant to lakeFS &gt;= v0.84.0, which causes the <a href="https://github.com/treeverse/lakeFS/issues/4775">GC Backup &amp; Restore job to break</a>.  Currently, we are working on a fix.</li>
    <li>GC Backup &amp; Restore is available from version 0.5.2 of lakeFS Spark client.</li>
    <li>It is compatible with Hadoop API versions 3.1.3 and higher.</li>
    <li>Note that the utility is not fast due to DistCp performance limitations. You may prefer to backup your whole storage namespace with <a href="https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10">AzCopy</a> / <a href="https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html">aws cp</a> / <a href="https://docs.lakefs.io/howto/copying.html#using-rclone">rclone</a>.</li>
  </ul>
<h4 class="no_toc" id="job-options">
  
  
    <a href="#job-options" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Job options
  
  
</h4>
    

  <p><strong>Enabled by default</strong></p>

  <ul>
    <li><code class="language-plaintext highlighter-rouge">-v</code>, to log additional info (path, size) in the SKIP/COPY log</li>
    <li><code class="language-plaintext highlighter-rouge">-direct</code> to write directly to destination paths, recommended when the destination is an object store</li>
    <li><code class="language-plaintext highlighter-rouge">-strategy=dynamic</code> to accelerate DistCp performance</li>
  </ul>

  <p><strong>Additional options</strong></p>

  <ul>
    <li><code class="language-plaintext highlighter-rouge">-log</code>, to configure the log path</li>
    <li><code class="language-plaintext highlighter-rouge">-m</code>, to set the max number of maps</li>
    <li><code class="language-plaintext highlighter-rouge">-bandwidth</code>, to specify bandwidth per map, in MB/second</li>
    <li><code class="language-plaintext highlighter-rouge">-numListstatusThreads</code>, number of threads to use for building file listing, max 40</li>
  </ul>

  <p>To configure the properties, set the following Hadoop properties:</p>

  <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark.hadoop.distcp.log.path
spark.hadoop.distcp.max.maps
spark.hadoop.distcp.map.bandwidth.mb
spark.hadoop.distcp.liststatus.threads 
</code></pre></div>  </div>
<h4 class="no_toc" id="running-gc-backup-and-restore">
  
  
    <a href="#running-gc-backup-and-restore" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Running GC backup and restore
  
  
</h4>
    

  <p>You can run GC backup and restore using <code class="language-plaintext highlighter-rouge">spark-submit</code> or using your preferred method of running Spark programs. 
Currently, GC backup and restore is available for Spark 3.1.2 and 3.2.1, but it may work for other versions.</p>

  <p>First, download the lakeFS Spark client Uber-jar. The Uber-jar can be found on a public S3 location:
<code class="language-plaintext highlighter-rouge">http://treeverse-clients-us-east.s3-website-us-east-1.amazonaws.com/lakefs-spark-client-312-hadoop3/${CLIENT_VERSION}/lakefs-spark-client-312-hadoop3-assembly-${CLIENT_VERSION}.jar</code>
<strong>Note</strong> GC backup and restore is available from version 0.5.2 of lakeFS Spark client.</p>

  <p>Running instructions:</p>
<h5 class="no_toc" id="backup-job">
  
  
    <a href="#backup-job" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Backup job
  
  
</h5>
    

  <div class="tabs">
    <ul>
    <li><a href="#aws-option">On AWS</a></li>
	<li><a href="#azure-option">On Azure</a></li>
  </ul>
    <div id="aws-option">

      <p>You should specify the Uber-jar path instead of <code class="language-plaintext highlighter-rouge">&lt;APPLICATION-JAR-PATH&gt;</code>
Program arguments:</p>
      <ul>
        <li><em>location of expired objects list</em>: the path of an expired objects parquet created by a <a href="#mark-only-mode">mark-only</a> GC run. given a <code class="language-plaintext highlighter-rouge">MARK_ID</code> used for a mark-only run this file is located under <code class="language-plaintext highlighter-rouge">STORAGE_NAMESPACE/_lakefs/retention/gc/addresses/mark_id=&lt;MARK_ID&gt;/</code>.</li>
        <li><em>storage namespace</em>: The storage namespace of the lakeFS repository you are running GC for. The storage namespace includes the data you are backing up.</li>
        <li><em>external location for backup</em>: A storage location outside your lakeFS storage namespace into which you want to save the backup.</li>
        <li><em>storage type</em>: s3</li>
      </ul>

      <p>To start the backup process, run:</p>

      <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit <span class="nt">--class</span> io.treeverse.clients.GCBackupAndRestore <span class="se">\</span>
  <span class="nt">--packages</span> org.apache.hadoop:hadoop-aws:3.2.0 <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.s3a.access.key<span class="o">=</span>&lt;AWS_ACCESS_KEY&gt; <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.s3a.secret.key<span class="o">=</span>&lt;AWS_SECRET_KEY&gt; <span class="se">\</span>
  &lt;APPLICATION-JAR-PATH&gt; <span class="se">\</span>
  expired-objects-list-location storage-namespace backup-external-location s3 
</code></pre></div>      </div>
    </div>

    <div id="azure-option">

      <p>You should specify the Uber-jar path instead of <code class="language-plaintext highlighter-rouge">&lt;APPLICATION-JAR-PATH&gt;</code>
Program arguments:</p>
      <ul>
        <li><em>location of expired objects list</em>: the path of an expired objects parquet created by a <a href="#mark-only-mode">mark-only</a> GC run. given a <code class="language-plaintext highlighter-rouge">MARK_ID</code> used for a mark-only run this file is located under <code class="language-plaintext highlighter-rouge">STORAGE_NAMESPACE/_lakefs/retention/gc/addresses/mark_id=&lt;MARK_ID&gt;/</code>.</li>
        <li><em>storage namespace</em>: The storage namespace of the lakeFS repository you are running GC for. The storage namespace includes the data you are backing up.</li>
        <li><em>external location for backup</em>: A storage location outside your lakeFS storage namespace into which you want to save the backup.</li>
        <li><em>storage type</em>: s3</li>
      </ul>

      <p>To start the backup process, run:</p>
      <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit <span class="nt">--class</span> io.treeverse.clients.GCBackupAndRestore <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.azure.account.key.&lt;AZURE_STORAGE_ACCOUNT&gt;.dfs.core.windows.net<span class="o">=</span>&lt;AZURE_STORAGE_ACCESS_KEY&gt; <span class="se">\</span>
  &lt;APPLICATION-JAR-PATH&gt; <span class="se">\</span>
  expired-objects-list-location storage-namespace backup-external-location azure
</code></pre></div>      </div>
    </div>
<h5 class="no_toc" id="restore-job">
  
  
    <a href="#restore-job" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Restore job
  
  
</h5>
    

    <div class="tabs">
      <ul>
    <li><a href="#aws-option">On AWS</a></li>
	<li><a href="#azure-option">On Azure</a></li>
  </ul>
      <div id="aws-option">

        <p>You should specify the Uber-jar path instead of <code class="language-plaintext highlighter-rouge">&lt;APPLICATION-JAR-PATH&gt;</code>
Program arguments:</p>
        <ul>
          <li><em>location of objects to restore list</em>: the path for a list of object that were hard-deleted by a <a href="#sweep-only-mode">sweep-only</a> GC run. given a <code class="language-plaintext highlighter-rouge">MARK_ID</code> used for a sweep only run the file is located under <code class="language-plaintext highlighter-rouge">STORAGE_NAMESPACE/_lakefs/retention/gc/addresses/mark_id=&lt;MARK_ID&gt;/</code>.</li>
          <li><em>external location to restore from</em>: A storage location outside your lakeFS storage namespace you used for backup.</li>
          <li><em>storage namespace</em>: The storage namespace of the lakeFS repository you previously ran GC for.</li>
          <li><em>storage type</em>: s3</li>
        </ul>

        <p>To start the restore process, run:</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit <span class="nt">--class</span> io.treeverse.clients.GCBackupAndRestore <span class="se">\</span>
 <span class="nt">--packages</span> org.apache.hadoop:hadoop-aws:3.2.0 <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.s3a.access.key<span class="o">=</span>&lt;AWS_ACCESS_KEY&gt; <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.s3a.secret.key<span class="o">=</span>&lt;AWS_SECRET_KEY&gt; <span class="se">\</span>
  &lt;APPLICATION-JAR-PATH&gt; <span class="se">\</span>
  objects-to-restore-list-location backup-external-location storage-namespace s3 
</code></pre></div>        </div>
      </div>

      <div id="azure-option">
        <p>You should specify the Uber-jar path instead of <code class="language-plaintext highlighter-rouge">&lt;APPLICATION-JAR-PATH&gt;</code>
Program arguments:</p>
        <ul>
          <li><em>location of objects to restore list</em>: the path for a list of object that were hard-deleted by a <a href="#sweep-only-mode">sweep-only</a> GC run. given a <code class="language-plaintext highlighter-rouge">MARK_ID</code> used for a sweep only run the file is located under <code class="language-plaintext highlighter-rouge">STORAGE_NAMESPACE/_lakefs/retention/gc/addresses/mark_id=&lt;MARK_ID&gt;/</code>.</li>
          <li><em>external location to restore from</em>: A storage location outside your lakeFS storage namespace you used for backup.</li>
          <li><em>storage namespace</em>: The storage namespace of the lakeFS repository you previously ran GC for.</li>
          <li><em>storage type</em>: azure</li>
        </ul>

        <p>To start the restore process, run:</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit <span class="nt">--class</span> io.treeverse.clients.GCBackupAndRestore <span class="se">\</span>
  <span class="nt">-c</span> spark.hadoop.fs.azure.account.key.&lt;AZURE_STORAGE_ACCOUNT&gt;.dfs.core.windows.net<span class="o">=</span>&lt;AZURE_STORAGE_ACCESS_KEY&gt; <span class="se">\</span>
  &lt;APPLICATION-JAR-PATH&gt; <span class="se">\</span>
  objects-to-restore-list-location backup-external-location storage-namespace azure
</code></pre></div>        </div>
      </div>
<h2 id="beta-deleting-uncommitted-objects">
  
  
    <a href="#beta-deleting-uncommitted-objects" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Beta: Deleting uncommitted objects
  
  
</h2>
    

      <p class="note">Note: Uncommitted GC is in Beta mode. Users should read this manual carefully and 
take precautions before applying the actual delete (“sweep”), like copying the marked objects.</p>

      <p>Deletion of objects that were never committed was always a difficulty for lakeFS, see
<a href="https://github.com/treeverse/lakeFS/issues/1933">#1933</a> for more details. Examples for 
objects that will be collected as part of the uncommitted GC job:</p>
      <ol>
        <li>Objects that were uploaded to lakeFS and deleted.</li>
        <li>Objects that were uploaded to lakeFS and were overridden.</li>
      </ol>

      <p class="note">While we tried to make the uncommitted GC a server-only solution, we couldn’t find a sustainable way to achieve that.
See discussion on the original <a href="https://github.com/treeverse/lakeFS/pull/4015">design PR</a>.</p>

      <p>The uncommitted GC will not clean:</p>
      <ol>
        <li>Committed objects. For committed objects cleanup see <a href="#what-gets-collected">above</a></li>
        <li>Everything mentioned in <a href="#what-does-_not_-get-collected">what does not get collected</a></li>
      </ol>
<h3 class="no_toc" id="prerequisites">
  
  
    <a href="#prerequisites" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Prerequisites
  
  
</h3>
    

      <ol>
        <li>lakeFS server version must be at least <a href="https://github.com/treeverse/lakeFS/releases/tag/v0.87.0">v0.87.0</a>. 
If your version is lower, you should first upgrade.</li>
        <li>Read the <a href="#limitations">limitations</a> section.</li>
        <li>Setup <a href="https://rclone.org/">rclone</a> to access underlying bucket for backup and restore.</li>
      </ol>
<h3 id="running-the-uncommitted-gc">
  
  
    <a href="#running-the-uncommitted-gc" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Running the uncommitted GC
  
  
</h3>
    

      <ol>
        <li>
          <p>Mark the files to delete - summary and report will be generated under <code class="language-plaintext highlighter-rouge">&lt;REPOSITORY_STORAGE_NAMESPACE&gt;/_lakefs/retention/gc/uncommitted/&lt;MARK_ID&gt;/</code>.
By listing the bucket under ‘uncommitted’ the last entry represents the last mark ID of the uncommitted GC.
The GC job prints out “Report for mark_id=…” which includes the mark ID with the run summary.</p>

          <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.gc.do_sweep<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.api.url<span class="o">=</span>&lt;LAKEFS_ENDPOINT&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.fs.s3a.access.key<span class="o">=</span>&lt;AWS_ACCESS_KEY_ID&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.fs.s3a.secret.key<span class="o">=</span>&lt;AWS_SECRET_ACCESS_KEY&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.api.access_key<span class="o">=</span>&lt;LAKEFS_ACCESS_KEY_ID&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.api.secret_key<span class="o">=</span>&lt;LAKEFS_SECRET_ACCESS_KEY&gt; <span class="se">\</span>
    <span class="nt">--class</span> io.treeverse.gc.UncommittedGarbageCollector <span class="se">\</span>
    <span class="nt">--packages</span> org.apache.hadoop:hadoop-aws:2.7.7 <span class="se">\</span>
    &lt;APPLICATION-JAR-PATH&gt; &lt;REPOSITORY_NAME&gt; &lt;REGION&gt;
</code></pre></div>          </div>
        </li>
        <li>
          <p>Backup (optional but recommended) - when you start using the feature you may want to first gain confidence in the decisions uncommitted GC makes. Backup will copy the objects marked to be deleted for run ID to a specified location.
Follow <a href="https://rclone.org/docs/">rclone documentation</a> to configure remote access to lakeFS storage.
Note that the lakeFS and backup locations are specified as <code class="language-plaintext highlighter-rouge">remote:path</code> based on how rclone was configured.</p>

          <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rclone <span class="nt">--include</span> <span class="s2">"*.txt"</span> <span class="nb">cat</span> <span class="s2">"&lt;LAKEFS_STORAGE_NAMESPACE&gt;/_lakefs/retention/gc/uncommitted/&lt;MARK_ID&gt;/deleted.text/"</span> | <span class="se">\</span>
  rclone <span class="nt">-P</span> <span class="nt">--no-traverse</span> <span class="nt">--files-from</span> - copy &lt;LAKEFS_STORAGE_NAMESPACE&gt; &lt;BACKUP_STORAGE_LOCATION&gt;
</code></pre></div>          </div>
        </li>
        <li>
          <p>Sweep - delete reported objects to delete based on mark ID</p>

          <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-submit <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.gc.mark_id<span class="o">=</span>&lt;MARK_ID&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.gc.do_mark<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.api.url<span class="o">=</span>&lt;LAKEFS_ENDPOINT&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.fs.s3a.access.key<span class="o">=</span>&lt;AWS_ACCESS_KEY_ID&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.fs.s3a.secret.key<span class="o">=</span>&lt;AWS_SECRET_ACCESS_KEY&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.api.access_key<span class="o">=</span>&lt;LAKEFS_ACCESS_KEY_ID&gt; <span class="se">\</span>
    <span class="nt">--conf</span> spark.hadoop.lakefs.api.secret_key<span class="o">=</span>&lt;LAKEFS_SECRET_ACCESS_KEY&gt; <span class="se">\</span>
    <span class="nt">--class</span> io.treeverse.gc.UncommittedGarbageCollector <span class="se">\</span>
    <span class="nt">--packages</span> org.apache.hadoop:hadoop-aws:2.7.7 <span class="se">\</span>
    &lt;APPLICATION-JAR-PATH&gt; &lt;REPOSITORY_NAME&gt; &lt;REGION&gt;
</code></pre></div>          </div>
        </li>
        <li>
          <p>Restore - in any case we would like to undo and restore the data from from our backup. The following command will copy the objects back from the backup location using the information stored under the specific mark ID.
Note that the lakeFS and backup locations are specified as <code class="language-plaintext highlighter-rouge">remote:path</code> based on how rclone was configured.</p>

          <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rclone <span class="nt">--include</span> <span class="s2">"*.txt"</span> <span class="nb">cat</span> <span class="s2">"remote:&lt;LAKEFS_STORAGE_NAMESPACE&gt;/_lakefs/retention/gc/uncommitted/&lt;MARK_ID&gt;/deleted.text/"</span> | <span class="se">\</span>
  rclone <span class="nt">-P</span> <span class="nt">--no-traverse</span> <span class="nt">--files-from</span> - copy &lt;BACKUP_STORAGE_LOCATION&gt; &lt;LAKEFS_STORAGE_NAMESPACE&gt;
</code></pre></div>          </div>
        </li>
      </ol>
<h4 class="no_toc" id="uncommitted-gc-job-options">
  
  
    <a href="#uncommitted-gc-job-options" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Uncommitted GC job options
  
  
</h4>
    

      <p>Similar to the described <a href="#gc-job-options">above</a>.</p>
<h4 class="no_toc" id="limitations">
  
  
    <a href="#limitations" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Limitations
  
  
</h4>
    

      <p>The uncommitted GC job has several limitations in its Beta version:</p>
      <ol>
        <li>No writes to lakeFS during the execution of the job. Objects written to lakeFS
during the job run may or may not be detected by the job. It can lead to unexpected behaviour 
including the deletion of newly written data. Avoid any write operation while the job is 
running, like <code class="language-plaintext highlighter-rouge">UploadObject</code>, <code class="language-plaintext highlighter-rouge">CopyObject</code>, <code class="language-plaintext highlighter-rouge">StageObject</code>, <code class="language-plaintext highlighter-rouge">LinkPhysicalAddress</code> or 
any other non-read operation.</li>
        <li>Support is limited to S3 repositories, it was not tested on ABS, GS or MinIO.</li>
        <li>Scale may be limited, see performance results below.</li>
      </ol>
<h4 class="no_toc" id="next-steps">
  
  
    <a href="#next-steps" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Next steps
  
  
</h4>
    

      <p>The uncommitted GC is under development, next releases will include:</p>

      <ol>
        <li>Incorporation of committed &amp; uncommitted GC into a single job. We understand the friction
of having 2 garbage collection jobs for a lakeFS installation and working to creating a
single job for it.</li>
        <li>Removing the limitation of a read-only lakeFS during the job run.</li>
        <li>Performance improvements:
          <ol>
            <li>Better parallelization of the storage namespace traversal.</li>
            <li>Optimized Run: GC will only iterate over objects that were written to the
repository since the last GC run. For more information see the <a href="https://github.com/treeverse/lakeFS/blob/master/design/accepted/gc_plus/uncommitted-gc.md#flow-2-optimized-run">proposal</a>.</li>
          </ol>
        </li>
        <li>Backup &amp; Restore, similar to <a href="#gc-backup-and-restore">committed data</a>.</li>
        <li>Support for non-S3 repositories.</li>
      </ol>
<h4 class="no_toc" id="performance-1">
  
  
    <a href="#performance-1" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Performance
  
  
</h4>
    

      <p>The uncommitted GC job was tested on a repository with 1K branches, 
25K uncommitted objects and 2K commits.
The storage namespace number of objects prior to the cleanup was 103K objects.
The job ran on a Spark cluster with a single master and 2 workers of type <a href="https://aws.amazon.com/ec2/instance-types/i3/">i3.2xlarge</a> 
The job finished after 5 minutes deleting 15K objects.</p>

    </div>
  </div>
</div>

                

                
                

            </div>
        </div>

        
        

        <div class="search-overlay"></div>
        
    </div>
</div>

<footer>
    <div class="footer-sidebar"></div>
    <div class="footer-main">
        <div class="row">
            <a href="https://lakefs.io" class="site-title lh-tight">
                <div class="site-logo"></div>
            </a>
        </div>
        <div class="row">
            <div class="left">
                <ul class="footer-links">
                    
                    
                    <li class="aux-nav-list-item">
                        <a href="https://docs.lakefs.io/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Docs
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/blog/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Blog
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://github.com/treeverse/lakeFS" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            GitHub
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/community/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Community
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/cloud-registration/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            lakeFS Cloud
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/contact-us/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Contact
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
            <div class="right">
                <ul class="footer-social">
                    
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/youtube" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.90/assets/icons/youtube.svg" class="no-hover" />
                            <img src="/v0.90/assets/icons/youtube-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://www.linkedin.com/company/treeverse" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.90/assets/icons/linkedin.svg" class="no-hover" />
                            <img src="/v0.90/assets/icons/linkedin-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://github.com/treeverse/lakeFS" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.90/assets/icons/github.svg" class="no-hover" />
                            <img src="/v0.90/assets/icons/github-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://twitter.com/lakeFS" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.90/assets/icons/twitter.svg" class="no-hover" />
                            <img src="/v0.90/assets/icons/twitter-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/slack" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.90/assets/icons/slack.svg" class="no-hover" />
                            <img src="/v0.90/assets/icons/slack-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
        <div class="row top-border">
            <div class="left"><a href="/v0.90https://www.treeverse.io/">
                    <div class="other-logo"><img src="/v0.90/assets/by-treeverse.png" /></div>
                </a></div>
            <div class="right">
                <ul class="bottom-footer-links">
                    
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/terms-of-use/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Terms of use
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/privacy-policy/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Privacy Policy
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
    </div>
</footer>


</body>

</html>

