

<!DOCTYPE html>

<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  

  <link rel="shortcut icon" href="/v0.48/favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="/v0.48/assets/css/just-the-docs-default.css">

  

  
    <script type="text/javascript" src="/v0.48/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="/v0.48/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Spark | lakeFS</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Spark" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Accessing data in lakeFS from Apache Spark is the same as accessing S3 data from Apache Spark" />
<meta property="og:description" content="Accessing data in lakeFS from Apache Spark is the same as accessing S3 data from Apache Spark" />
<meta property="og:site_name" content="lakeFS" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Spark" />
<script type="application/ld+json">
{"description":"Accessing data in lakeFS from Apache Spark is the same as accessing S3 data from Apache Spark","@type":"WebPage","url":"/v0.48/integrations/spark.html","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/v0.48/assets/logo.svg"}},"headline":"Spark","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Google Tag Manager Head -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-KTZBZW9');</script>
<!-- End Google Tag Manager Head -->
<meta name="robots" content="noindex">
<meta property="og:image" content="/v0.48/assets/img/shared-image.png">
<script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/js/fontawesome.min.js" integrity="sha512-i3N2a3sMtKOQHXCJF3qEpce5twcGN9mRsWQe6PUTf9WS/eG5XkivI97uxit7B2nRGz5XuoszBaqndSqxdeVfag==" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
<script src="https://code.jquery.com/jquery-3.5.1.min.js"
        integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
        crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/themes/smoothness/jquery-ui.css">
<script src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
<script src="/v0.48/assets/js/copy-code.js"></script>
<script>
    $(function () {
        $(".tabs").tabs();
    });
</script>


</head>

<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KTZBZW9"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-link" viewBox="0 0 24 24">
        <title>Link</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
             class="feather feather-link">
            <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
            <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
        </svg>
    </symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
        <title>Search</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
             class="feather feather-search">
            <circle cx="11" cy="11" r="8"></circle>
            <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
        </svg>
    </symbol>
    <symbol id="svg-menu" viewBox="0 0 24 24">
        <title>Menu</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="20px" height="16px" viewBox="0 0 20 16" version="1.1"
             class="feather feather-menu">
            <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
                <g id="header-/-mobile" transform="translate(-30.000000, -32.000000)" fill="#279890">
                    <g id="Group" transform="translate(30.000000, 32.000000)">
                        <path
                                d="M20,14 L20,16 L0,16 L0,14 L20,14 Z M20,7 L20,9 L0,9 L0,7 L20,7 Z M20,0 L20,2 L0,2 L0,0 L20,0 Z"
                                id="mobile-menu" />
                    </g>
                </g>
            </g>
        </svg>
    </symbol>
    <symbol id="svg-arrow-right" viewBox="0 0 24 24">
        <title>Expand</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
             class="feather feather-chevron-right">
            <polyline points="9 18 15 12 9 6"></polyline>
        </svg>
    </symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
        <title>Document</title>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
             stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
             class="feather feather-file">
            <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path>
            <polyline points="13 2 13 9 20 9"></polyline>
        </svg>
    </symbol>
</svg>
<div class="body-wrapper">
    <div class="side-bar">
        <div class="site-header">
            <a href="https://lakefs.io" class="site-title lh-tight">
  <div class="site-logo"></div>

</a>
            <a href="#" id="menu-button" class="site-button">
                <svg viewBox="0 0 24 24" class="icon">
                    <use xlink:href="#svg-menu"></use>
                </svg>
            </a>
        </div>
        <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav">
            
            <div class="search">
                <div class="search-input-wrap">
                    <input type="text" id="search-input" class="search-input" tabindex="0"
                           placeholder="Search lakeFS" aria-label="Search lakeFS"
                           autocomplete="off">
                    <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon">
                            <use xlink:href="#svg-search"></use>
                        </svg></label>
                </div>
                <div id="search-results" class="search-results"></div>
            </div>
            

            <div class="nav-category nav-version">
                <label for="selectversion">Version:</label>
                <select id="selectversion" name="version" onchange="javascript:location.href = '/' + this.value;">
                    <option value="" selected>Latest</option>
                </select>
            </div>
            <script async>
                window.addEventListener("load",  async () => {
                    const pathFirstLevel = location.pathname.split('/')[1];
                    const selectedVersion = pathFirstLevel.startsWith('v') && pathFirstLevel || '';
                    const selectVersionElmFirst = document.getElementById('selectversion').firstElementChild;
                    const response = await fetch('/versions.json');
                    if (!response.ok) {
                        return
                    }
                    const versions = await response.json();
                    versions.reverse();
                    for (let versionObj of versions) {
                        const el = document.createElement("option");
                        el.value = versionObj.version;
                        el.textContent = versionObj.title;
                        if (versionObj.version === selectedVersion) {
                            el.selected = true;
                        }
                        selectVersionElmFirst.after(el);
                    }
                });
            </script>

            <ul class="nav-list"><li
            class="nav-list-item"><a href="/v0.48/"
           class="nav-list-link">What is lakeFS</a></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.48/quickstart/"
           class="nav-list-link">Quickstart</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.48/quickstart/installing.html"
                   class="nav-list-link">Install lakeFS</a></li><li class="nav-list-item "><a href="/v0.48/quickstart/repository.html"
                   class="nav-list-link">Create a Repository</a></li><li class="nav-list-item "><a href="/v0.48/quickstart/aws_cli.html"
                   class="nav-list-link">Add Data</a></li><li class="nav-list-item "><a href="/v0.48/quickstart/lakefs_cli.html"
                   class="nav-list-link">Install lakeFS CLI</a></li><li class="nav-list-item "><a href="/v0.48/quickstart/more_quickstart_options.html"
                   class="nav-list-link">More Quickstart Options</a></li><li class="nav-list-item "><a href="/v0.48/quickstart/try.html"
                   class="nav-list-link">Try without installing</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.48/deploy/"
           class="nav-list-link">Deploy lakeFS</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.48/deploy/aws.html"
                   class="nav-list-link">On AWS</a></li><li class="nav-list-item "><a href="/v0.48/deploy/azure.html"
                   class="nav-list-link">On Azure</a></li><li class="nav-list-item "><a href="/v0.48/deploy/gcp.html"
                   class="nav-list-link">On GCP</a></li><li class="nav-list-item "><a href="/v0.48/deploy/k8s.html"
                   class="nav-list-link">With Kubernetes</a></li><li class="nav-list-item "><a href="/v0.48/deploy/docker.html"
                   class="nav-list-link">With Docker</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.48/setup/"
           class="nav-list-link">Setup lakeFS</a><ul class="nav-list "><li class="nav-list-item "><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                        <use xlink:href="#svg-arrow-right"></use>
                    </svg></a><a href="/v0.48/setup/storage/"
                   class="nav-list-link">Prepare Your Storage</a><ul class="nav-list"><li class="nav-list-item ">
                        <a href="/v0.48/setup/storage/s3.html"
                           class="nav-list-link">AWS S3</a>
                    </li><li class="nav-list-item ">
                        <a href="/v0.48/setup/storage/gcs.html"
                           class="nav-list-link">Google Cloud Storage</a>
                    </li><li class="nav-list-item ">
                        <a href="/v0.48/setup/storage/blob.html"
                           class="nav-list-link">Azure Blob Storage</a>
                    </li></ul></li><li class="nav-list-item "><a href="/v0.48/setup/create-repo.html"
                   class="nav-list-link">Create a Repository</a></li><li class="nav-list-item "><a href="/v0.48/setup/import.html"
                   class="nav-list-link">Import data into lakeFS</a></li><li class="nav-list-item "><a href="/v0.48/setup/hooks.html"
                   class="nav-list-link">Hooks</a></li><li class="nav-list-item "><a href="/v0.48/setup/virtual-host-addressing.html"
                   class="nav-list-link">S3 Virtual-host addressing (advanced)</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.48/usecases/"
           class="nav-list-link">Using lakeFS</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.48/usecases/data-devenv.html"
                   class="nav-list-link">In Development</a></li><li class="nav-list-item "><a href="/v0.48/usecases/ci.html"
                   class="nav-list-link">During Deployment</a></li><li class="nav-list-item "><a href="/v0.48/usecases/production.html"
                   class="nav-list-link">In Production</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.48/reference/"
           class="nav-list-link">Reference</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.48/reference/api.html"
                   class="nav-list-link">API Reference</a></li><li class="nav-list-item "><a href="/v0.48/reference/s3.html"
                   class="nav-list-link">S3 Supported API</a></li><li class="nav-list-item "><a href="/v0.48/reference/configuration.html"
                   class="nav-list-link">Configuration Reference</a></li><li class="nav-list-item "><a href="/v0.48/reference/commands.html"
                   class="nav-list-link">Command (CLI) Reference</a></li><li class="nav-list-item "><a href="/v0.48/reference/export.html"
                   class="nav-list-link">Exporting Data</a></li><li class="nav-list-item "><a href="/v0.48/reference/garbage-collection.html"
                   class="nav-list-link">Garbage Collection</a></li><li class="nav-list-item "><a href="/v0.48/reference/monitor.html"
                   class="nav-list-link">Monitoring using Prometheus</a></li><li class="nav-list-item "><a href="/v0.48/reference/offboarding.html"
                   class="nav-list-link">Migrating away from lakeFS</a></li><li class="nav-list-item "><a href="/v0.48/reference/upgrade.html"
                   class="nav-list-link">Upgrade lakeFS</a></li><li class="nav-list-item "><a href="/v0.48/reference/authorization.html"
                   class="nav-list-link">Authentication & Authorization</a></li><li class="nav-list-item "><a href="/v0.48/reference/object-model.html"
                   class="nav-list-link">Object Model</a></li></ul></li><li
            class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.48/integrations/"
           class="nav-list-link">Integrations</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.48/integrations/distcp.html"
                   class="nav-list-link">Copying Data with DistCp</a></li><li class="nav-list-item "><a href="/v0.48/integrations/rclone.html"
                   class="nav-list-link">Copying data with Rclone</a></li><li class="nav-list-item "><a href="/v0.48/integrations/aws_cli.html"
                   class="nav-list-link">AWS CLI</a></li><li class="nav-list-item  active"><a href="/v0.48/integrations/spark.html"
                   class="nav-list-link active">Spark</a></li><li class="nav-list-item "><a href="/v0.48/integrations/hive.html"
                   class="nav-list-link">Hive</a></li><li class="nav-list-item "><a href="/v0.48/integrations/python.html"
                   class="nav-list-link">Python</a></li><li class="nav-list-item "><a href="/v0.48/integrations/emr.html"
                   class="nav-list-link">EMR</a></li><li class="nav-list-item "><a href="/v0.48/integrations/presto_trino.html"
                   class="nav-list-link">Presto/Trino</a></li><li class="nav-list-item "><a href="/v0.48/integrations/boto.html"
                   class="nav-list-link">Boto (Python)</a></li><li class="nav-list-item "><a href="/v0.48/integrations/minio.html"
                   class="nav-list-link">MinIO</a></li><li class="nav-list-item "><a href="/v0.48/integrations/athena.html"
                   class="nav-list-link">Amazon Athena</a></li><li class="nav-list-item "><a href="/v0.48/integrations/airflow.html"
                   class="nav-list-link">Airflow</a></li><li class="nav-list-item "><a href="/v0.48/integrations/kubeflow.html"
                   class="nav-list-link">Kubeflow</a></li><li class="nav-list-item "><a href="/v0.48/integrations/airbyte.html"
                   class="nav-list-link">Airbyte</a></li><li class="nav-list-item "><a href="/v0.48/integrations/databricks.html"
                   class="nav-list-link">Databricks</a></li><li class="nav-list-item "><a href="/v0.48/integrations/delta.html"
                   class="nav-list-link">Delta Lake</a></li><li class="nav-list-item "><a href="/v0.48/integrations/glue_hive_metastore.html"
                   class="nav-list-link">Glue / Hive metastore</a></li><li class="nav-list-item "><a href="/v0.48/integrations/glue_etl.html"
                   class="nav-list-link">Glue ETL</a></li><li class="nav-list-item "><a href="/v0.48/integrations/kakfa.html"
                   class="nav-list-link">Kafka</a></li><li class="nav-list-item "><a href="/v0.48/integrations/mapreduce.html"
                   class="nav-list-link">MapReduce</a></li><li class="nav-list-item "><a href="/v0.48/integrations/sagemaker.html"
                   class="nav-list-link">SageMaker</a></li><li class="nav-list-item "><a href="/v0.48/integrations/dremio.html"
                   class="nav-list-link">Dremio</a></li></ul></li><li
            class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24">
                <use xlink:href="#svg-arrow-right"></use>
            </svg></a><a href="/v0.48/understand/"
           class="nav-list-link">Understanding lakeFS</a><ul class="nav-list "><li class="nav-list-item "><a href="/v0.48/understand/architecture.html"
                   class="nav-list-link">Architecture</a></li><li class="nav-list-item "><a href="/v0.48/understand/data-model.html"
                   class="nav-list-link">Data Model</a></li><li class="nav-list-item "><a href="/v0.48/understand/branching-model.html"
                   class="nav-list-link">Branching Model</a></li><li class="nav-list-item "><a href="/v0.48/understand/sizing-guide.html"
                   class="nav-list-link">Sizing Guide</a></li><li class="nav-list-item "><a href="/v0.48/understand/roadmap.html"
                   class="nav-list-link">Roadmap</a></li><li class="nav-list-item "><a href="/v0.48/understand/licensing.html"
                   class="nav-list-link">Licensing</a></li></ul></li><li
            class="nav-list-item"><a href="/v0.48/contributing.html"
           class="nav-list-link">Contributing</a></li><li
            class="nav-list-item"><a href="/v0.48/faq.html"
           class="nav-list-link">FAQ</a></li></ul>
            <div class="mobile-menu">
                
<nav aria-label="Auxiliary" class="aux-nav">
    <ul class="aux-nav-list">
        
        
        <li class="aux-nav-list-item">
            <a href="https://docs.lakefs.io/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Docs
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://github.com/treeverse/lakeFS" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                GitHub
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://lakefs.io/blog/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Blog
            </a>
        </li>
        
        
        
        
        <li class="aux-nav-list-item button">
            <a href="https://docs.lakefs.io/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Get Started
            </a>
        </li>
        
        
    </ul>
</nav>

            </div>
        </nav>

    </div>
    <div class="main" id="top">
        <div id="main-header" class="main-header">
            
<nav aria-label="Auxiliary" class="aux-nav">
    <ul class="aux-nav-list">
        
        
        <li class="aux-nav-list-item">
            <a href="https://docs.lakefs.io/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Docs
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://github.com/treeverse/lakeFS" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                GitHub
            </a>
        </li>
        
        <li class="aux-nav-list-item">
            <a href="https://lakefs.io/blog/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Blog
            </a>
        </li>
        
        
        
        
        <li class="aux-nav-list-item button">
            <a href="https://docs.lakefs.io/" class="site-button"  target="_blank"
               rel="noopener noreferrer" >
                Get Started
            </a>
        </li>
        
        
    </ul>
</nav>

        </div>
        <div id="main-content-wrap" class="main-content-wrap">
            
            
            <nav aria-label="Breadcrumb" class="breadcrumb-nav">
                <ol class="breadcrumb-nav-list">
                    
                    <li class="breadcrumb-nav-list-item"><a href="/v0.48/integrations/">Integrations</a>
                    </li>
                    
                    <li class="breadcrumb-nav-list-item"><span>Spark</span></li>
                </ol>
            </nav>
            
            
            <div id="main-content" class="main-content" role="main">
                
                <h1 class="no_toc" id="using-lakefs-with-spark">
        
        
          <a href="#using-lakefs-with-spark" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Using lakeFS with Spark
        
        
      </h1>
    
<p><a href="https://spark.apache.org/">Apache Spark</a> is a unified analytics engine for big data processing, with built-in modules for streaming, SQL, machine learning and graph processing.</p>

<div class="toc-block pb-5">
      <h2 class="no_toc text-delta" id="table-of-contents">
        
        
          <a href="#table-of-contents" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of contents
        
        
      </h2>
    

<ol id="markdown-toc">
  <li><a href="#two-tiered-spark-support" id="markdown-toc-two-tiered-spark-support">Two-tiered Spark support</a></li>
  <li><a href="#access-lakefs-using-the-s3a-gateway" id="markdown-toc-access-lakefs-using-the-s3a-gateway">Access lakeFS using the S3A gateway</a>    <ol>
      <li><a href="#configuration" id="markdown-toc-configuration">Configuration</a>        <ol>
          <li><a href="#per-bucket-configuration" id="markdown-toc-per-bucket-configuration">Per-bucket configuration</a></li>
        </ol>
      </li>
      <li><a href="#reading-data" id="markdown-toc-reading-data">Reading Data</a></li>
      <li><a href="#writing-data" id="markdown-toc-writing-data">Writing Data</a></li>
    </ol>
  </li>
  <li><a href="#access-lakefs-using-the-lakefs-specific-hadoop-filesystem" id="markdown-toc-access-lakefs-using-the-lakefs-specific-hadoop-filesystem">Access lakeFS using the lakeFS-specific Hadoop FileSystem</a>    <ol>
      <li><a href="#configuration-1" id="markdown-toc-configuration-1">Configuration</a>        <ol>
          <li><a href="#load-the-filesystem-jars" id="markdown-toc-load-the-filesystem-jars">Load the FileSystem JARs</a></li>
          <li><a href="#configure-the-lakefs-filesystem-and-the-underlying-s3a-filesystem" id="markdown-toc-configure-the-lakefs-filesystem-and-the-underlying-s3a-filesystem">Configure the lakeFS FileSystem and the underlying S3A FileSystem</a></li>
          <li><a href="#per-bucket-and-per-repo-configuration" id="markdown-toc-per-bucket-and-per-repo-configuration">Per-bucket and per-repo configuration</a></li>
        </ol>
      </li>
      <li><a href="#reading-data-1" id="markdown-toc-reading-data-1">Reading Data</a></li>
      <li><a href="#writing-data-1" id="markdown-toc-writing-data-1">Writing Data</a></li>
    </ol>
  </li>
  <li><a href="#case-study-similarweb" id="markdown-toc-case-study-similarweb">Case Study: SimilarWeb</a></li>
</ol>

</div>

<p class="note"><strong>Note</strong> In all following examples we set AWS and lakeFS credentials at runtime, for
clarity. In production, properties defining AWS credentials should be set using one of
Hadoop’s standard ways of <a href="https://hadoop.apache.org/docs/current/hadoop-aws/tools/hadoop-aws/index.html#Authenticating_with_S3" target="_blank">authenticating with
S3</a>.
Similarly, properties defining lakeFS credentials should be configured in secure site files,
not on the command line or inlined in code where they might be exposed.</p>
      <h2 id="two-tiered-spark-support">
        
        
          <a href="#two-tiered-spark-support" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Two-tiered Spark support
        
        
      </h2>
    

<p>lakeFS support in Spark has two tiers:</p>

<ul>
  <li>Access lakeFS using the <a href="#access-lakefs-using-the-s3a-gateway">S3A gateway</a>.</li>
  <li>Access lakeFS using the <a href="#access-lakefs-using-the-lakefs-specific-hadoop-filesystem">lakeFS-specific Hadoop
FileSystem</a>.</li>
</ul>

<p>Using the S3A gateway is easier to configure and may be more suitable for legacy or
small-scale applications.  Using the lakeFS FileSystem requires somewhat more complex
configuration, but offers greatly increased performance.</p>
      <h2 id="access-lakefs-using-the-s3a-gateway">
        
        
          <a href="#access-lakefs-using-the-s3a-gateway" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Access lakeFS using the S3A gateway
        
        
      </h2>
    

<p>To use this mode you configure the Spark application to use S3A using the S3-compatible
endpoint which the lakeFS server provides.  Accordingly all data flows through the lakeFS
server.</p>

<p>Accessing data in lakeFS from Spark is the same as accessing S3 data from Spark.  The only
changes we need to consider are:</p>
<ol>
  <li>Setting the configurations to access lakeFS.</li>
  <li>Accessing objects using the lakeFS S3 path convention.</li>
</ol>
      <h3 id="configuration">
        
        
          <a href="#configuration" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Configuration
        
        
      </h3>
    

<p>In order to configure Spark to work with lakeFS, we set S3 Hadoop configuration to the lakeFS endpoint and credentials:</p>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th>Hadoop Configuration</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.s3a.access.key</code></td>
      <td>Set to the lakeFS access key</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.s3a.secret.key</code></td>
      <td>Set to the lakeFS secret key</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.s3a.endpoint</code></td>
      <td>Set to the lakeFS S3-compatible API endpoint</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.s3a.path.style.access</code></td>
      <td>Set to <code class="language-plaintext highlighter-rouge">true</code></td>
    </tr>
  </tbody>
</table></div>

<p>Here is how to do it:</p>
<div class="tabs">
  <ul>
    <li><a href="#s3-config-tabs-cli">CLI</a></li>
    <li><a href="#s3-config-tabs-code">Scala</a></li>
    <li><a href="#s3-config-tabs-xml">XML Configuration</a></li>
  </ul>
  <div id="s3-config-tabs-cli">
    <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-shell <span class="nt">--conf</span> spark.hadoop.fs.s3a.access.key<span class="o">=</span><span class="s1">'AKIAlakefs12345EXAMPLE'</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.s3a.secret.key<span class="o">=</span><span class="s1">'abc/lakefs/1234567bPxRfiCYEXAMPLEKEY'</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.s3a.path.style.access<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.s3a.endpoint<span class="o">=</span><span class="s1">'https://lakefs.example.com'</span> ...
</code></pre></div>    </div>
  </div>
  <div id="s3-config-tabs-code">
    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.access.key"</span><span class="o">,</span> <span class="s">"AKIAlakefs12345EXAMPLE"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.secret.key"</span><span class="o">,</span> <span class="s">"abc/lakefs/1234567bPxRfiCYEXAMPLEKEY"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.endpoint"</span><span class="o">,</span> <span class="s">"https://lakefs.example.com"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.path.style.access"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">)</span>
</code></pre></div>    </div>
  </div>
  <div id="s3-config-tabs-xml">
    <p>Add these into a configuration file, e.g. <code class="language-plaintext highlighter-rouge">$SPARK_HOME/conf/hdfs-site.xml</code>:</p>
    <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0"?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.access.key<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>AKIAlakefs12345EXAMPLE<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
            <span class="nt">&lt;name&gt;</span>fs.s3a.secret.key<span class="nt">&lt;/name&gt;</span>
            <span class="nt">&lt;value&gt;</span>abc/lakefs/1234567bPxRfiCYEXAMPLEKEY<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.endpoint<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>https://lakefs.example.com<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.path.style.access<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>    </div>
  </div>
</div>
      <h4 id="per-bucket-configuration">
        
        
          <a href="#per-bucket-configuration" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Per-bucket configuration
        
        
      </h4>
    

<p>The above configuration will use lakeFS as the sole S3 endpoint. To use lakeFS in parallel with S3, you can configure Spark to use lakeFS only for specific bucket names.
For example, to configure only <code class="language-plaintext highlighter-rouge">example-repo</code> to use lakeFS, set the following configurations:</p>

<div class="tabs">
  <ul>
    <li><a href="#s3-bucket-config-tabs-cli">CLI</a></li>
    <li><a href="#s3-bucket-config-tabs-code">Scala</a></li>
    <li><a href="#s3-bucket-config-tabs-xml">XML Configuration</a></li>
  </ul>
  <div id="s3-bucket-config-tabs-cli">
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-shell <span class="nt">--conf</span> spark.hadoop.fs.s3a.bucket.example-repo.access.key<span class="o">=</span><span class="s1">'AKIAlakefs12345EXAMPLE'</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.s3a.bucket.example-repo.secret.key<span class="o">=</span><span class="s1">'abc/lakefs/1234567bPxRfiCYEXAMPLEKEY'</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.s3a.bucket.example-repo.endpoint<span class="o">=</span><span class="s1">'https://lakefs.example.com'</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.s3a.path.style.access<span class="o">=</span><span class="nb">true</span>
</code></pre></div>    </div>
  </div>
  <div id="s3-bucket-config-tabs-code">
    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.bucket.example-repo.access.key"</span><span class="o">,</span> <span class="s">"AKIAlakefs12345EXAMPLE"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.bucket.example-repo.secret.key"</span><span class="o">,</span> <span class="s">"abc/lakefs/1234567bPxRfiCYEXAMPLEKEY"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.bucket.example-repo.endpoint"</span><span class="o">,</span> <span class="s">"https://lakefs.example.com"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.path.style.access"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">)</span>
</code></pre></div>    </div>
  </div>
  <div id="s3-bucket-config-tabs-xml">
    <p>Add these into a configuration file, e.g. <code class="language-plaintext highlighter-rouge">$SPARK_HOME/conf/hdfs-site.xml</code>:</p>
    <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0"?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.bucket.example-repo.access.key<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>AKIAlakefs12345EXAMPLE<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.bucket.example-repo.secret.key<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>abc/lakefs/1234567bPxRfiCYEXAMPLEKEY<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.bucket.example-repo.endpoint<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>https://lakefs.example.com<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.path.style.access<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>    </div>
  </div>
</div>

<p>With this configuration set , reading s3a paths with <code class="language-plaintext highlighter-rouge">example-repo</code> as the bucket will use lakeFS, while all other buckets will use AWS S3.</p>
      <h3 id="reading-data">
        
        
          <a href="#reading-data" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Reading Data
        
        
      </h3>
    
<p>In order for us to access objects in lakeFS we will need to use the lakeFS S3 gateway path
conventions:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>s3a://[REPOSITORY]/[BRANCH]/PATH/TO/OBJECT
</code></pre></div></div>

<p>Here is an example for reading a parquet file from lakeFS to a Spark DataFrame:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">repo</span> <span class="k">=</span> <span class="s">"example-repo"</span>
<span class="k">val</span> <span class="nv">branch</span> <span class="k">=</span> <span class="s">"main"</span>
<span class="k">val</span> <span class="nv">dataPath</span> <span class="k">=</span> <span class="n">s</span><span class="s">"s3a://${repo}/${branch}/example-path/example-file.parquet"</span>

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">parquet</span><span class="o">(</span><span class="n">dataPath</span><span class="o">)</span>
</code></pre></div></div>

<p>You can now use this DataFrame like you would normally do.</p>
      <h3 id="writing-data">
        
        
          <a href="#writing-data" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Writing Data
        
        
      </h3>
    

<p>Now simply write your results back to a lakeFS path:</p>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">df</span><span class="o">.</span><span class="py">write</span><span class="o">.</span><span class="py">partitionBy</span><span class="o">(</span><span class="s">"example-column"</span><span class="o">).</span><span class="py">parquet</span><span class="o">(</span><span class="n">s</span><span class="s">"s3a://${repo}/${branch}/output-path/"</span><span class="o">)</span>
</code></pre></div></div>

<p>The data is now created in lakeFS as new changes in your branch. You can now commit these changes, or revert them.</p>
      <h2 id="access-lakefs-using-the-lakefs-specific-hadoop-filesystem">
        
        
          <a href="#access-lakefs-using-the-lakefs-specific-hadoop-filesystem" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Access lakeFS using the lakeFS-specific Hadoop FileSystem
        
        
      </h2>
    

<p>To use this mode you configure the Spark application to perform metadata operations on the
lakeFS server, and all data operations directly through the same underlying object store that
lakeFS uses.  The lakeFS FileSystem currently supports Spark with Hadoop Apache 2.7 using only the S3A Hadoop FileSystem
for data access.  In this mode the Spark application will directly read and write from the
underlying object store, significantly increasing application scalability and performance by
reducing the load on the lakeFS server.</p>

<p>Accessing data in lakeFS from Spark is the same as accessing S3 data from Spark.  The only
changes we need to perform are:</p>

<ol>
  <li>Configure Spark to access lakeFS for metadata and S3 or a compatible underlying object
store to access data.</li>
  <li>Use <code class="language-plaintext highlighter-rouge">lakefs://repo/ref/path/to/data</code> URIs to read and write data on lakeFS, rather than
<code class="language-plaintext highlighter-rouge">s3a://...</code> URIs.</li>
</ol>
      <h3 id="configuration-1">
        
        
          <a href="#configuration-1" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Configuration
        
        
      </h3>
    

<p>In order to configure Spark to work using the lakeFS Hadoop FileSystem, you will need to load
the filesystem JARs and then configure both that FileSystem and the underlying data access
FileSystem.</p>
      <h4 id="load-the-filesystem-jars">
        
        
          <a href="#load-the-filesystem-jars" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Load the FileSystem JARs
        
        
      </h4>
    

<p>Add the package <code class="language-plaintext highlighter-rouge">io.lakefs:hadoop-lakefs-assembly:&lt;VERSION&gt;</code> to your Spark job.  Right now
this is version 0.1.0, so add:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>--packages io.lakefs:hadoop-lakefs-assembly:0.1.0
</code></pre></div></div>

<p>to your Spark commandlines.</p>
      <h4 id="configure-the-lakefs-filesystem-and-the-underlying-s3a-filesystem">
        
        
          <a href="#configure-the-lakefs-filesystem-and-the-underlying-s3a-filesystem" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Configure the lakeFS FileSystem and the underlying S3A FileSystem
        
        
      </h4>
    

<p>Add Hadoop configuration to the underlying storage and additionally to lakeFS credentials.
When using this mode, do <strong>not</strong> set the S3A endpoint URL to point at lakeFS – it should
point at the underlying storage.</p>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th>Hadoop Configuration</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.s3a.access.key</code></td>
      <td>Set to the AWS S3 access key</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.s3a.secret.key</code></td>
      <td>Set to the AWS S3 secret key</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.s3a.endpoint</code></td>
      <td>Set to the AWS S3-compatible endpoint</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.lakefs.impl</code></td>
      <td><code class="language-plaintext highlighter-rouge">io.lakefs.LakeFSFileSystem</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.lakefs.access.key</code></td>
      <td>Set to the lakeFS access key</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.lakefs.secret.key</code></td>
      <td>Set to the lakeFS secret key</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">fs.lakefs.endpoint</code></td>
      <td>Set to the lakeFS API URL</td>
    </tr>
  </tbody>
</table></div>

<p>When using AWS S3 itself, the default configuration works with us-east-1, so you may still
need to configure <code class="language-plaintext highlighter-rouge">fs.s3a.endpoint</code>.  Amazon provides these <a href="https://docs.aws.amazon.com/general/latest/gr/s3.html">S3
endpoints</a> you can use.</p>

<p><strong>Note:</strong> If not running on AWS, all s3a configuration properties are required!  Unlike when
using the S3 gateway, when using the lakeFS-specific Hadoop FileSystem you configure <code class="language-plaintext highlighter-rouge">s3a</code> to
access the S3 underlying object storage, and <code class="language-plaintext highlighter-rouge">lakefs</code> to access the lakeFS server.  When
running on AWS you do not need to configure credentials if the instance profile has sufficient
permissions.</p>

<p>Here is how to do it:</p>
<div class="tabs">
  <ul>
    <li><a href="#lakefs-config-tabs-cli">CLI</a></li>
    <li><a href="#lakefs-config-tabs-code">Scala</a></li>
    <li><a href="#lakefs-config-tabs-xml">XML Configuration</a></li>
  </ul>
  <div id="lakefs-config-tabs-cli">
    <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>spark-shell <span class="nt">--conf</span> spark.hadoop.fs.s3a.access.key<span class="o">=</span><span class="s1">'AKIAIOSFODNN7EXAMPLE'</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.s3a.secret.key<span class="o">=</span><span class="s1">'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.s3a.endpoint<span class="o">=</span><span class="s1">'https://s3.eu-central-1.amazonaws.com'</span> <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.lakefs.impl<span class="o">=</span>io.lakefs.LakeFSFileSystem <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.lakefs.access.key<span class="o">=</span>AKIAlakefs12345EXAMPLE <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.lakefs.secret.key<span class="o">=</span>abc/lakefs/1234567bPxRfiCYEXAMPLEKEY <span class="se">\</span>
              <span class="nt">--conf</span> spark.hadoop.fs.lakefs.endpoint<span class="o">=</span>https://lakefs.example.com/api/v1 <span class="se">\</span>
              <span class="nt">--packages</span> io.lakefs:hadoop-lakefs-assembly:0.1.0
              ...
</code></pre></div>    </div>
  </div>
  <div id="lakefs-config-tabs-code">

    <p>Ensure you load the lakeFS FileSystem into Spark by running it with <code class="language-plaintext highlighter-rouge">--packages</code> or <code class="language-plaintext highlighter-rouge">--jars</code>,
and then run:</p>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.access.key"</span><span class="o">,</span> <span class="s">"AKIAIOSFODNN7EXAMPLE"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.secret.key"</span><span class="o">,</span> <span class="s">"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.s3a.endpoint"</span><span class="o">,</span> <span class="s">"https://s3.eu-central-1.amazonaws.com"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.lakefs.impl"</span><span class="o">,</span> <span class="s">"io.lakefs.LakeFSFileSystem"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.lakefs.access.key"</span><span class="o">,</span> <span class="s">"AKIAlakefs12345EXAMPLE"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.lakefs.secret.key"</span><span class="o">,</span> <span class="s">"abc/lakefs/1234567bPxRfiCYEXAMPLEKEY"</span><span class="o">)</span>
<span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">hadoopConfiguration</span><span class="o">.</span><span class="py">set</span><span class="o">(</span><span class="s">"fs.lakefs.endpoint"</span><span class="o">,</span> <span class="s">"https://lakefs.example.com/api/v1"</span><span class="o">)</span>
</code></pre></div>    </div>
  </div>
  <div id="lakefs-config-tabs-xml">

    <p>Ensure you load the lakeFS FileSystem into Spark by running it with <code class="language-plaintext highlighter-rouge">--packages</code> or <code class="language-plaintext highlighter-rouge">--jars</code>,
and then add these into a configuration file, e.g. <code class="language-plaintext highlighter-rouge">$SPARK_HOME/conf/hdfs-site.xml</code>:</p>

    <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0"?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.access.key<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>AKIAIOSFODNN7EXAMPLE<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
            <span class="nt">&lt;name&gt;</span>fs.s3a.secret.key<span class="nt">&lt;/name&gt;</span>
            <span class="nt">&lt;value&gt;</span>wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.s3a.endpoint<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>https://s3.eu-central-1.amazonaws.com<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.lakefs.impl<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>io.lakefs.LakeFSFileSystem<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.lakefs.access.key<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>AKIAlakefs12345EXAMPLE<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.lakefs.secret.key<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>abc/lakefs/1234567bPxRfiCYEXAMPLEKEY<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.lakefs.endpoint<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>https://lakefs.example.com/api/v1<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div>    </div>
  </div>
</div>
      <h4 id="per-bucket-and-per-repo-configuration">
        
        
          <a href="#per-bucket-and-per-repo-configuration" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Per-bucket and per-repo configuration
        
        
      </h4>
    

<p>As above, S3 allows for per-bucket configuration.  You can use this if:</p>

<ol>
  <li>You need to use S3A directly to access data in an S3 outside of lakeFS, <em>and</em></li>
  <li>different credentials are required to access data inside that bucket.</li>
</ol>

<p>Refer to the Hadoop AWS guide on <a href="https://hadoop.apache.org/docs/current/hadoop-aws/tools/hadoop-aws/index.html#Configuring_different_S3_buckets_with_Per-Bucket_Configuration">Configuring different S3 buckets with Per-Bucket
Configuration</a>.</p>

<p>There is no need for per-repo configurations in lakeFS when all repositories are on the same
lakeFS server.  If you need to access repositories that are on <em>multiple</em> lakeFS servers,
configure multiple prefixes.  For instance, you might configure both <code class="language-plaintext highlighter-rouge">fs.lakefs.impl</code> and
<code class="language-plaintext highlighter-rouge">fs.lakefs2.impl</code> to be <code class="language-plaintext highlighter-rouge">io.lakefs.LakeFSFileSystem</code>, place separate endpoints and credentials
under <code class="language-plaintext highlighter-rouge">fs.lakefs.*</code> and <code class="language-plaintext highlighter-rouge">fs.lakefs2.*</code>, and access the two servers using <code class="language-plaintext highlighter-rouge">lakefs://...</code> and
<code class="language-plaintext highlighter-rouge">lakefs2://...</code> URLs.</p>
      <h3 id="reading-data-1">
        
        
          <a href="#reading-data-1" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Reading Data
        
        
      </h3>
    
<p>In order for us to access objects in lakeFS we will need to use the lakeFS path conventions:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lakefs://[REPOSITORY]/[BRANCH]/PATH/TO/OBJECT
</code></pre></div></div>

<p>Here is an example for reading a parquet file from lakeFS to a Spark DataFrame:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">repo</span> <span class="k">=</span> <span class="s">"example-repo"</span>
<span class="k">val</span> <span class="nv">branch</span> <span class="k">=</span> <span class="s">"main"</span>
<span class="k">val</span> <span class="nv">dataPath</span> <span class="k">=</span> <span class="n">s</span><span class="s">"lakefs://${repo}/${branch}/example-path/example-file.parquet"</span>

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">parquet</span><span class="o">(</span><span class="n">dataPath</span><span class="o">)</span>
</code></pre></div></div>

<p>You can now use this DataFrame like you would normally do.</p>
      <h3 id="writing-data-1">
        
        
          <a href="#writing-data-1" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Writing Data
        
        
      </h3>
    

<p>Now simply write your results back to a lakeFS path:</p>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">df</span><span class="o">.</span><span class="py">write</span><span class="o">.</span><span class="py">partitionBy</span><span class="o">(</span><span class="s">"example-column"</span><span class="o">).</span><span class="py">parquet</span><span class="o">(</span><span class="n">s</span><span class="s">"lakefs://${repo}/${branch}/output-path/"</span><span class="o">)</span>
</code></pre></div></div>

<p>The data is now created in lakeFS as new changes in your branch. You can now commit these changes, or revert them.</p>
      <h2 id="case-study-similarweb">
        
        
          <a href="#case-study-similarweb" class="anchor-heading"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Case Study: SimilarWeb
        
        
      </h2>
    

<p>See how SimilarWeb is using lakeFS with Spark to <a href="https://grdoron.medium.com/a-smarter-way-to-manage-algorithm-changes-in-data-pipelines-with-lakefs-a4e284f8c756">manage algorithm changes in data pipelines</a>.</p>

                

                


            </div>
        </div>

        
        

        <div class="search-overlay"></div>
        
    </div>
</div>

<footer>
    <div class="footer-sidebar"></div>
    <div class="footer-main">
        <div class="row">
            <a href="https://lakefs.io" class="site-title lh-tight">
                <div class="site-logo"></div>
            </a>
        </div>
        <div class="row">
            <div class="left">
                <ul class="footer-links">
                    
                    
                    <li class="aux-nav-list-item">
                        <a href="https://docs.lakefs.io/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Docs
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://github.com/treeverse/lakeFS" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            GitHub
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/blog/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Blog
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/contact-us/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Contact
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
            <div class="right">
                <ul class="footer-social">
                    
                    
                    <li class="aux-nav-list-item">
                        <a href="https://www.linkedin.com/company/treeverse" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.48/assets/icons/linkedin.svg" class="no-hover" />
                            <img src="/v0.48/assets/icons/linkedin-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://github.com/treeverse/lakeFS" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.48/assets/icons/github.svg" class="no-hover" />
                            <img src="/v0.48/assets/icons/github-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://twitter.com/lakeFS" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.48/assets/icons/twitter.svg" class="no-hover" />
                            <img src="/v0.48/assets/icons/twitter-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/slack" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            <img src="/v0.48/assets/icons/slack.svg" class="no-hover" />
                            <img src="/v0.48/assets/icons/slack-hover.svg" class="hover" />
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
        <div class="row top-border">
            <div class="left"><a href="/v0.48https://www.treeverse.io/">
                    <div class="other-logo"><img src="/v0.48/assets/by-treeverse.png" /></div>
                </a></div>
            <div class="right">
                <ul class="bottom-footer-links">
                    
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/terms-of-use/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Terms of use
                        </a>
                    </li>
                    
                    <li class="aux-nav-list-item">
                        <a href="https://lakefs.io/privacy-policy/" class="site-button"  target="_blank"
                            rel="noopener noreferrer" >
                            Privacy Policy
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
    </div>
</footer>


</body>

</html>

